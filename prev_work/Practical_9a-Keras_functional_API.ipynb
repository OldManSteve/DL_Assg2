{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Practical 9a - Keras Functional API</h2><h3>AY2020/21 Semester</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to the functional API\n",
    "In the functional API, you directly manipulate tensors, and you use layers as functions\n",
    "that take tensors and return tensors (hence, the name functional API):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, layers\n",
    "input_tensor = Input(shape=(32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(32, activation='relu')\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start with a minimal example that shows side by side a simple Sequential model\n",
    "and its equivalent in the functional API:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***A Sequential Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***A Functional API Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only part that may seem a bit magical at this point is instantiating a `Model` object\n",
    "using only an input tensor and an output tensor. Behind the scenes, Keras retrieves\n",
    "every layer involved in going from `input_tensor` to `output_tensor`, bringing them\n",
    "together into a graph-like data structure—a `Model`. Of course, the reason it works is\n",
    "that `output_tensor` was obtained by repeatedly transforming `input_tensor`.\n",
    "\n",
    "When it comes to compiling, training, or evaluating such an instance of `Model`, the\n",
    "API is the same as that of Sequential:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics =['acc'])\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build a multiple inputs model using functional API\n",
    "We will build a question-answering model using functional API. The model has two inputs: a natural-language question\n",
    "and a text snippet (such as a news article) providing information to be used for answering the question. The model merge two input branches using a `concatenate` layer, after that model produce an answer via a softmax over some predefined vocabulary.\n",
    "\n",
    "First, we build up model using funcational API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(100,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(100,),dtype='int32',name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size,32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question],axis=-1)\n",
    "answer = layers.Dense(answer_vocabulary_size,activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we generate some dummy inputs (text, questions, answers) using `numpy` random number generation fuction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "answers = np.random.randint(0, answer_vocabulary_size, size=(num_samples, answer_vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the model using the above dummy inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes = True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

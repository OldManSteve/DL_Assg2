{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Assignment_2_p2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OE5jwFcdI52_"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68EISnjDIzDr",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"table table-bordered\">\n",
        "    <tr>\n",
        "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
        "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 2 - Character Generator Model (Problem 2)</h2><h3>AY2020/21 Semester</h3></th>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O40ionLYIzDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cc8a9d1-d190-4582-b533-9237aa2dd92e"
      },
      "source": [
        "# Import the Required Packages\n",
        "# Enter your code here:\n",
        "from tensorflow import keras\n",
        "print('keras: ', keras.__version__)\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras:  2.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:95% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4oJIdijtkeY",
        "colab_type": "text"
      },
      "source": [
        "### GitHub + Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz90Yb82trAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e36f779e-df9f-4e22-fcca-8d55fd65a196"
      },
      "source": [
        "#run for GitHub Colab\n",
        "!git clone \"https://github.com/OldManSteve/DL_Assg2.git\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DL_Assg2'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 51 (delta 15), reused 42 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxwhU0xHtsdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GitHub Colab directory\n",
        "# Directories for files\n",
        "holmes_file = '/content/DL_Assg2/holmes.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUg9FIRJ2vOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "20ddd4e2-d4b9-47e5-87d3-e3fc66cd3ea7"
      },
      "source": [
        "#Google drive model upload/save storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path='/content/drive/My Drive/Colab Notebooks/DL_Assg2_Models/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BXl__WTIzDw",
        "colab_type": "text"
      },
      "source": [
        "## Step 1 – Data Loading and Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApFnQPRIzDw",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edsqbjtrIzDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ba403c3-9d71-4be6-e7fa-a6e5dbc6d188"
      },
      "source": [
        "# read in the text file, transforming everything to lower case\n",
        "text = open(holmes_file).read().lower()\n",
        "print('The original text has ' + str(len(text)) + ' characters.\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The original text has 562422 characters.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga5JfFmVIzDy",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Data Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFCH3DmGIzDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "194260ef-c943-46de-c525-81c3ef2e758a"
      },
      "source": [
        "### print out the first 1000 characters of the raw text to get a sense of what characters to remove\n",
        "text[:2000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ufeffthe adventures of sherlock holmes by sir arthur conan doyle\\n\\n   i. a scandal in bohemia\\n  ii. the red-headed league\\n iii. a case of identity\\n  iv. the boscombe valley mystery\\n   v. the five orange pips\\n  vi. the man with the twisted lip\\n vii. the adventure of the blue carbuncle\\nviii. the adventure of the speckled band\\n  ix. the adventure of the engineer's thumb\\n   x. the adventure of the noble bachelor\\n  xi. the adventure of the beryl coronet\\n xii. the adventure of the copper beeches\\n\\n\\nadventure i. a scandal in bohemia\\n\\ni.\\n\\nto sherlock holmes she is always the woman. i have seldom heard\\nhim mention her under any other name. in his eyes she eclipses\\nand predominates the whole of her sex. it was not that he felt\\nany emotion akin to love for irene adler. all emotions, and that\\none particularly, were abhorrent to his cold, precise but\\nadmirably balanced mind. he was, i take it, the most perfect\\nreasoning and observing machine that the world has seen, but as a\\nlover he would have placed himself in a false position. he never\\nspoke of the softer passions, save with a gibe and a sneer. they\\nwere admirable things for the observer--excellent for drawing the\\nveil from men's motives and actions. but for the trained reasoner\\nto admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a distracting factor which\\nmight throw a doubt upon all his mental results. grit in a\\nsensitive instrument, or a crack in one of his own high-power\\nlenses, would not be more disturbing than a strong emotion in a\\nnature such as his. and yet there was but one woman to him, and\\nthat woman was the late irene adler, of dubious and questionable\\nmemory.\\n\\ni had seen little of holmes lately. my marriage had drifted us\\naway from each other. my own complete happiness, and the\\nhome-centred interests which rise up around the man who first\\nfinds himself master of his own establishment, were sufficient to\\nabsorb all my attention, while holmes, who loathed every form of\\nsociety \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGWz3AusIzD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "40613b0e-933b-426a-9300-62a6f298ad07"
      },
      "source": [
        "# remove all '\\n' and '\\r' from text\n",
        "text = text.replace('\\n','') \n",
        "text = text.replace('\\r','')\n",
        "\n",
        "print(text[:2000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿the adventures of sherlock holmes by sir arthur conan doyle   i. a scandal in bohemia  ii. the red-headed league iii. a case of identity  iv. the boscombe valley mystery   v. the five orange pips  vi. the man with the twisted lip vii. the adventure of the blue carbuncleviii. the adventure of the speckled band  ix. the adventure of the engineer's thumb   x. the adventure of the noble bachelor  xi. the adventure of the beryl coronet xii. the adventure of the copper beechesadventure i. a scandal in bohemiai.to sherlock holmes she is always the woman. i have seldom heardhim mention her under any other name. in his eyes she eclipsesand predominates the whole of her sex. it was not that he feltany emotion akin to love for irene adler. all emotions, and thatone particularly, were abhorrent to his cold, precise butadmirably balanced mind. he was, i take it, the most perfectreasoning and observing machine that the world has seen, but as alover he would have placed himself in a false position. he neverspoke of the softer passions, save with a gibe and a sneer. theywere admirable things for the observer--excellent for drawing theveil from men's motives and actions. but for the trained reasonerto admit such intrusions into his own delicate and finelyadjusted temperament was to introduce a distracting factor whichmight throw a doubt upon all his mental results. grit in asensitive instrument, or a crack in one of his own high-powerlenses, would not be more disturbing than a strong emotion in anature such as his. and yet there was but one woman to him, andthat woman was the late irene adler, of dubious and questionablememory.i had seen little of holmes lately. my marriage had drifted usaway from each other. my own complete happiness, and thehome-centred interests which rise up around the man who firstfinds himself master of his own establishment, were sufficient toabsorb all my attention, while holmes, who loathed every form ofsociety with his whole bohemian soul, remained in our\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39LI1iTOIzD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a function 'clean_text' to clean text so that only the following letters and punctation remain\n",
        "def clean_text(text):\n",
        "    punctuation = ['!', ',', '.', ':', ';', '?', '-', \"'\",' ']\n",
        "    letters='abcdefghijklmnopqrstuvwxyz'\n",
        "    \n",
        "    # Enter your code here:\n",
        "    clean_text=''\n",
        "\n",
        "    for i in text:\n",
        "      if i in punctuation or i in letters:\n",
        "        clean_text+=i\n",
        "\n",
        "    return clean_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsGJWaVnIzD5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "9a3d213b-1c1a-4a3c-bb92-3861ec3f2741"
      },
      "source": [
        "# clean data using clean_text function\n",
        "text = clean_text(text)\n",
        "text[:2000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the adventures of sherlock holmes by sir arthur conan doyle   i. a scandal in bohemia  ii. the red-headed league iii. a case of identity  iv. the boscombe valley mystery   v. the five orange pips  vi. the man with the twisted lip vii. the adventure of the blue carbuncleviii. the adventure of the speckled band  ix. the adventure of the engineer's thumb   x. the adventure of the noble bachelor  xi. the adventure of the beryl coronet xii. the adventure of the copper beechesadventure i. a scandal in bohemiai.to sherlock holmes she is always the woman. i have seldom heardhim mention her under any other name. in his eyes she eclipsesand predominates the whole of her sex. it was not that he feltany emotion akin to love for irene adler. all emotions, and thatone particularly, were abhorrent to his cold, precise butadmirably balanced mind. he was, i take it, the most perfectreasoning and observing machine that the world has seen, but as alover he would have placed himself in a false position. he neverspoke of the softer passions, save with a gibe and a sneer. theywere admirable things for the observer--excellent for drawing theveil from men's motives and actions. but for the trained reasonerto admit such intrusions into his own delicate and finelyadjusted temperament was to introduce a distracting factor whichmight throw a doubt upon all his mental results. grit in asensitive instrument, or a crack in one of his own high-powerlenses, would not be more disturbing than a strong emotion in anature such as his. and yet there was but one woman to him, andthat woman was the late irene adler, of dubious and questionablememory.i had seen little of holmes lately. my marriage had drifted usaway from each other. my own complete happiness, and thehome-centred interests which rise up around the man who firstfinds himself master of his own establishment, were sufficient toabsorb all my attention, while holmes, who loathed every form ofsociety with his whole bohemian soul, remained in our \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etvZzKpxIzD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "98f2a6fd-79fd-4b4d-e2e2-75caf935e798"
      },
      "source": [
        "# count the number of unique characters in the text\n",
        "chars = sorted(list(set(text)))\n",
        "\n",
        "# print some of the text, as well as statistics\n",
        "print (\"This document has \" +  str(len(text)) + \" total number of characters.\")\n",
        "print (\"This document has \" +  str(len(chars)) + \" unique characters.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This document has 544340 total number of characters.\n",
            "This document has 35 unique characters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31dPYdLxIzD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a function 'generate_text_io' to generate text inputs based on window_size and the corresponding labels\n",
        "def generate_text_io(text, window_size):\n",
        "    inputs = [] # store inputs\n",
        "    labels = [] # stores label\n",
        "    \n",
        "    # Enter your code here:\n",
        "    for i in range(0, len(text)-window_size):\n",
        "      inputs.append(text[i:i+window_size])\n",
        "      labels.append(text[i+window_size])\n",
        "    \n",
        "    print(\"Num of Sequences: \",len(inputs))\n",
        "    print(inputs)\n",
        "    return inputs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj42ZA8tIzD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this dictionary is a function mapping each unique character to a unique integer\n",
        "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
        "\n",
        "# this dictionary is a function mapping each unique integer back to a unique character\n",
        "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrqDoltLIzEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# create a function 'encode_io_pairs' to perform one-hot encoding of inputs and labels\n",
        "def encode_io_pairs(text,window_size): # window_size determines # of characters in each input\n",
        "    \n",
        "    # Enter your code here:\n",
        "    inputs, labels = generate_text_io(text, window_size)\n",
        "\n",
        "\n",
        "    # Next, one-hot encode the characters into binary arrays.\n",
        "    print('Vectorization...')\n",
        "    x = np.zeros((len(inputs), window_size, len(chars)), dtype=np.bool)\n",
        "    y = np.zeros((len(inputs), len(chars)), dtype=np.bool)\n",
        "    for i, sentence in enumerate(inputs):\n",
        "        for t, char in enumerate(sentence):\n",
        "            x[i, t, chars_to_indices[char]] = 1\n",
        "        y[i, chars_to_indices[labels[i]]] = 1\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeeuHDQLIzEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5485024c-c587-420a-bf79-0a8e18121160"
      },
      "source": [
        "# perform one-hot encoding of inputs and labels\n",
        "window_size = 100\n",
        "X, y = encode_io_pairs(text, window_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of Sequences:  544240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pBlfPVcIzEE",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Splitting Dataset into Inputs (X) and Labels (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ob1YhtcIzEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f77af48a-62ad-433a-af4c-559bbee05058"
      },
      "source": [
        "# Note: You may choose to perform this step before encoding the data (step 1.2).\n",
        "# Enter your code here:\n",
        "print (y.shape)\n",
        "print (X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(544240, 35)\n",
            "(544240, 100, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMsx4elxIzEG",
        "colab_type": "text"
      },
      "source": [
        "## Step 2 – Develop a Character Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16qkySXvrkWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x8o5qVagyyXk"
      },
      "source": [
        "### Model TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD81gHNby5VW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "dcab8e41-8152-4251-bb62-8d9d19a82ed3"
      },
      "source": [
        "!git clone https://github.com/minimaxir/char-embeddings.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'char-embeddings'...\n",
            "remote: Enumerating objects: 152, done.\u001b[K\n",
            "remote: Total 152 (delta 0), reused 0 (delta 0), pack-reused 152\u001b[K\n",
            "Receiving objects: 100% (152/152), 10.95 MiB | 6.04 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DST4j60NFkLd",
        "colab": {}
      },
      "source": [
        "max_words = 10000\n",
        "embedding_dim = 300\n",
        "\n",
        "glove_dir = '/content/char-embeddings/'\n",
        "\n",
        "embedding_vectors = {}\n",
        "with open(glove_dir + 'glove.840B.300d-char.txt') as f:\n",
        "    for line in f:\n",
        "        line_split = line.strip().split(\" \")\n",
        "        vec = np.array(line_split[1:], dtype=float)\n",
        "        char = line_split[0]\n",
        "        embedding_vectors[char] = vec\n",
        "\n",
        "embedding_matrix = np.zeros((len(chars), 300))\n",
        "#embedding_matrix = np.random.uniform(-1, 1, (len(chars), 300))\n",
        "for char, i in chars_to_indices.items():\n",
        "    #print (\"{}, {}\".format(char, i))\n",
        "    embedding_vector = embedding_vectors.get(char)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6W8w0zLlmkwV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "15d08c75-9d1c-47aa-a098-a65018c1fb8d"
      },
      "source": [
        "# Build the Model\n",
        "# Enter your code here:\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Embedding(max_words, embedding_dim, input_shape=(window_size, len(chars))))\n",
        "model.add(layers.Flatten())\n",
        "#model.add(layers.Dense(128, input_shape=(window_size, len(chars)))) #multiclass single label classification\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 100, 35, 300)      3000000   \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1050000)           0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               134400128 \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 35)                4515      \n",
            "=================================================================\n",
            "Total params: 137,404,643\n",
            "Trainable params: 137,404,643\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjE-eJ59yyXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6b183577-b1e6-4787-d657-1d4b2d7c99fc"
      },
      "source": [
        "# Train the Model\n",
        "# Enter your code here:\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['acc'])\n",
        "\n",
        "history = model.fit(X, y,\n",
        "                    epochs=10,\n",
        "                    batch_size=256) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2126/2126 [==============================] - 1623s 763ms/step - loss: 2.4436 - acc: 0.3004\n",
            "Epoch 2/10\n",
            "2126/2126 [==============================] - 1625s 764ms/step - loss: 2.1061 - acc: 0.3839\n",
            "Epoch 3/10\n",
            "2126/2126 [==============================] - 1625s 765ms/step - loss: 1.9910 - acc: 0.4125\n",
            "Epoch 4/10\n",
            "2126/2126 [==============================] - 1627s 765ms/step - loss: 1.9085 - acc: 0.4345\n",
            "Epoch 5/10\n",
            "2126/2126 [==============================] - 1625s 764ms/step - loss: 1.8396 - acc: 0.4539\n",
            "Epoch 6/10\n",
            "2126/2126 [==============================] - 1622s 763ms/step - loss: 1.7822 - acc: 0.4697\n",
            "Epoch 7/10\n",
            "2126/2126 [==============================] - 1622s 763ms/step - loss: 1.7336 - acc: 0.4830\n",
            "Epoch 8/10\n",
            "2126/2126 [==============================] - 1626s 765ms/step - loss: 1.6923 - acc: 0.4950\n",
            "Epoch 9/10\n",
            "2126/2126 [==============================] - 1625s 764ms/step - loss: 1.6576 - acc: 0.5048\n",
            "Epoch 10/10\n",
            "2126/2126 [==============================] - 1617s 761ms/step - loss: 1.6272 - acc: 0.5127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m74FOpfoyyXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "a67c2c23-4a97-4a37-d4e8-5fdedb33c469"
      },
      "source": [
        "# Plot the Training and Validation Accuracy & Loss Scores\n",
        "# Enter your code here:\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJSw8d3gyyXr",
        "colab": {}
      },
      "source": [
        "# Save the Model\n",
        "model.save(model_path+'chgen_model_gLove300d_1_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE5jwFcdI52_",
        "colab_type": "text"
      },
      "source": [
        "### Model #1 (Replicate as necessary for other models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RchO2-ZUI53D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1fdb4b5c-e4df-44fe-8477-c54bdcac8a9d"
      },
      "source": [
        "# Build the Model\n",
        "# Enter your code here:\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(window_size, len(chars)))) #multiclass single label classification\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               83968     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 35)                4515      \n",
            "=================================================================\n",
            "Total params: 88,483\n",
            "Trainable params: 88,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5TvSPvgI53G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "268281ce-a623-431c-a4b2-a2d33235cda0"
      },
      "source": [
        "# Train the Model\n",
        "# Enter your code here:\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['acc'])\n",
        "\n",
        "history = model.fit(X, y,\n",
        "                    epochs=30,\n",
        "                    batch_size=128) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "  92/4252 [..............................] - ETA: 19:05 - loss: 2.7630 - acc: 0.2216"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1c49725177cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(X, y,\n\u001b[1;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     batch_size=128) \n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LIpw4rJI53K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the Training and Validation Accuracy & Loss Scores\n",
        "# Enter your code here:\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duLUdKGdI53k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the Model\n",
        "model.save('chgen_model_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3eGGato66L7v"
      },
      "source": [
        "### Model #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EcF77sSb6L7w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1fdb4b5c-e4df-44fe-8477-c54bdcac8a9d"
      },
      "source": [
        "# Build the Model\n",
        "# Enter your code here:\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Embbeding(max_words, ))\n",
        "model.add(layers.LSTM(128, input_shape=(window_size, len(chars)))) #multiclass single label classification\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               83968     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 35)                4515      \n",
            "=================================================================\n",
            "Total params: 88,483\n",
            "Trainable params: 88,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj_pt7iR6L7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "268281ce-a623-431c-a4b2-a2d33235cda0"
      },
      "source": [
        "# Train the Model\n",
        "# Enter your code here:\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['acc'])\n",
        "\n",
        "history = model.fit(X, y,\n",
        "                    epochs=30,\n",
        "                    batch_size=128) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "  92/4252 [..............................] - ETA: 19:05 - loss: 2.7630 - acc: 0.2216"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1c49725177cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(X, y,\n\u001b[1;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     batch_size=128) \n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MQf7lj4i6L7z",
        "colab": {}
      },
      "source": [
        "# Plot the Training and Validation Accuracy & Loss Scores\n",
        "# Enter your code here:\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "18HhyBvi6L71",
        "colab": {}
      },
      "source": [
        "# Save the Model\n",
        "model.save('chgen_model_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ih38IjmYlQPJ"
      },
      "source": [
        "## Step Evaluation [MODEL TESTING]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mhjaIJ85lQPL",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "\n",
        "#model.load_weights('chgen_model_best.h5')\n",
        "\n",
        "model = models.load_model(model_path+'chgen_model_gLove300d_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CrglYXR4lQPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "331ad337-cf9a-4006-8784-7b0cce88b1a3"
      },
      "source": [
        "# takes the user input\n",
        "\n",
        "#Oh's third victim was hawker stall owner Ng Phek Huay, whom he stole from on Sept 9, 2019.  While Madam Ng, 71, was waiting for her turn to see the doctor at Queenstown Polyclinic, he stole money from her handbag.  He then offered her zopiclone and convinced her that she had to take it before her medical check-up.  Thinking that Oh was one of the polyclinic staff, Madam Ng took the drug and became drowsy.  He then took from her a gold-coloured bracelet which she was wearing and took her out of the polyclinic.  Oh then got a taxi to take Madam Ng to NUH, as she was losing consciousness.  On Friday, District Judge Gwee backdated Oh's sentence to Sept 12 last year, when he was first remanded.\n",
        "\n",
        "#text_input = np.array([input()])\n",
        "text_input = clean_text(input().lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i love going to the park, especially when it is windy or sunny. every satruday i go to the park after buying ice cream.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EyrQPuFdlQPP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fdffde5c-f8e3-4057-b9d0-d253fb6a1371"
      },
      "source": [
        "# one-hot encode the user input\n",
        "# Enter your code here:\n",
        "new_window_size = 5\n",
        "\n",
        "X, y = encode_io_pairs(text_input, new_window_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of Sequences:  114\n",
            "['i lov', ' love', 'love ', 'ove g', 've go', 'e goi', ' goin', 'going', 'oing ', 'ing t', 'ng to', 'g to ', ' to t', 'to th', 'o the', ' the ', 'the p', 'he pa', 'e par', ' park', 'park,', 'ark, ', 'rk, e', 'k, es', ', esp', ' espe', 'espec', 'speci', 'pecia', 'ecial', 'ciall', 'ially', 'ally ', 'lly w', 'ly wh', 'y whe', ' when', 'when ', 'hen i', 'en it', 'n it ', ' it i', 'it is', 't is ', ' is w', 'is wi', 's win', ' wind', 'windy', 'indy ', 'ndy o', 'dy or', 'y or ', ' or s', 'or su', 'r sun', ' sunn', 'sunny', 'unny.', 'nny. ', 'ny. e', 'y. ev', '. eve', ' ever', 'every', 'very ', 'ery s', 'ry sa', 'y sat', ' satr', 'satru', 'atrud', 'truda', 'ruday', 'uday ', 'day i', 'ay i ', 'y i g', ' i go', 'i go ', ' go t', 'go to', 'o to ', ' to t', 'to th', 'o the', ' the ', 'the p', 'he pa', 'e par', ' park', 'park ', 'ark a', 'rk af', 'k aft', ' afte', 'after', 'fter ', 'ter b', 'er bu', 'r buy', ' buyi', 'buyin', 'uying', 'ying ', 'ing i', 'ng ic', 'g ice', ' ice ', 'ice c', 'ce cr', 'e cre', ' crea', 'cream']\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eC84ZvkwlQPQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "df07c53f-e48b-4afc-d4af-9cac479d4442"
      },
      "source": [
        "# show the model output using predict function\n",
        "# Enter your code here:\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "  \n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(X, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text_input) - new_window_size - 1)\n",
        "    generated_text = text_input[start_index: start_index + new_window_size]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ temperature:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # We generate 400 characters\n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, new_window_size, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"embedding_input_1:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 5, 35).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b26c307c5d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     model.fit(X, y,\n\u001b[1;32m     20\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m               epochs=1)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Select a text seed at random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 1050000 but received input with shape [None, 52500]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Or8q6OkOlQPS",
        "colab": {}
      },
      "source": [
        "model.fit(X, y, batch_size=128, epochs=1)\n",
        "\n",
        "text_input = input(\"Enter sentence to predict next character: \\n\")\n",
        "temperature = 0.2\n",
        "print('------ temperature:', temperature)\n",
        "print(\"Prediction: \")\n",
        "sys.stdout.write(text_input)\n",
        "\n",
        "# We generate 400 characters\n",
        "# for i in range(400):\n",
        "sampled = np.zeros((1, len(text_input), len(chars)))\n",
        "for t, char in enumerate(text_input):\n",
        "    sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "preds = model.predict(sampled, verbose=0)[0]\n",
        "next_index = sample(preds, temperature)\n",
        "next_char = chars[next_index]\n",
        "\n",
        "text_input += next_char\n",
        "text_input = text_input[1:]\n",
        "\n",
        "\n",
        "sys.stdout.write(next_char)\n",
        "sys.stdout.flush()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Q41dnxD5XCB"
      },
      "source": [
        "## Step 3 – Use the Best Model to make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sn9HJbJB5XCC",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "\n",
        "model = models.load_model(model_path+ 'chgen_model_best.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c1LlaagD5XCE",
        "colab": {}
      },
      "source": [
        "# takes the user input\n",
        "\n",
        "#text_input = np.array([input()])\n",
        "text_input = clean_text(input().lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMA3kSyI5XCH",
        "colab": {}
      },
      "source": [
        "# one-hot encode the user input\n",
        "# Enter your code here:\n",
        "new_window_size = 5\n",
        "\n",
        "X, y = encode_io_pairs(text_input, new_window_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-nLcyeIo5XCI",
        "colab": {}
      },
      "source": [
        "# show the model output using predict function\n",
        "# Enter your code here:\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "  \n",
        "#sequences = tokenizer.texts_to_sequences(text_input)\n",
        "#data = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(X, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text_input) - window_size - 1)\n",
        "    generated_text = text_input[start_index: start_index + window_size]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    #for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        #print('------ temperature:', temperature)\n",
        "    sys.stdout.write(generated_text)\n",
        "\n",
        "    # We generate 400 characters\n",
        "    for i in range(400):\n",
        "        sampled = np.zeros((1, window_size, len(chars)))\n",
        "        for t, char in enumerate(generated_text):\n",
        "            sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(sampled, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = chars[next_index]\n",
        "\n",
        "        generated_text += next_char\n",
        "        generated_text = generated_text[1:]\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "        print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JoBc7bGQ5XCK",
        "colab": {}
      },
      "source": [
        "model.fit(X, y, batch_size=128, epochs=1)\n",
        "\n",
        "text_input = input(\"Enter sentence to predict next character: \\n\")\n",
        "temperature = 0.2\n",
        "print('------ temperature:', temperature)\n",
        "print(\"Prediction: \")\n",
        "sys.stdout.write(text_input)\n",
        "\n",
        "# We generate 400 characters\n",
        "# for i in range(400):\n",
        "sampled = np.zeros((1, len(text_input), len(chars)))\n",
        "for t, char in enumerate(text_input):\n",
        "    sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "preds = model.predict(sampled, verbose=0)[0]\n",
        "next_index = sample(preds, temperature)\n",
        "next_char = chars[next_index]\n",
        "\n",
        "text_input += next_char\n",
        "text_input = text_input[1:]\n",
        "\n",
        "\n",
        "sys.stdout.write(next_char)\n",
        "sys.stdout.flush()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
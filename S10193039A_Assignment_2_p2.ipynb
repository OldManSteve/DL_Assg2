{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Assignment_2_p2_COMPILED01.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OE5jwFcdI52_",
        "iFmcWR9hzqbX",
        "NpbQekZs3113",
        "7KdVbmPf044x",
        "0V715IPMBL14",
        "Ak6JSxfpEP3T",
        "S-TPPhFjMsIJ",
        "Wu2dmE5d2z-b",
        "GMEeJqg-cok4",
        "hW2yIq9fdRie",
        "4aZGfZMdTMx-",
        "U7uZ3fnxVlWd",
        "gTX-bygdgcvn",
        "yjNpewYDhpfw",
        "MtJfwtEiltYX",
        "Vbn-T-WLyR68",
        "N5ngk1Zm6LR4",
        "VL1No9ojXiqs",
        "yH8_cts-IzEN",
        "00hEQbZIezdF",
        "vsrSzmfD9S0e",
        "-Q41dnxD5XCB"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68EISnjDIzDr",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"table table-bordered\">\n",
        "    <tr>\n",
        "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
        "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 2 - Character Generator Model (Problem 2)</h2><h3>AY2020/21 Semester</h3></th>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O40ionLYIzDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c019659-eb89-405c-cdc1-ab65cf5685f7"
      },
      "source": [
        "# Import the Required Packages\n",
        "# Enter your code here:\n",
        "from tensorflow import keras\n",
        "print('keras: ', keras.__version__)\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras:  2.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:95% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4oJIdijtkeY",
        "colab_type": "text"
      },
      "source": [
        "### GitHub + Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz90Yb82trAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a3fc890c-69aa-4fa8-d04a-332a4345e41c"
      },
      "source": [
        "#run for GitHub Colab\n",
        "!git clone \"https://github.com/OldManSteve/DL_Assg2.git\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DL_Assg2'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 51 (delta 15), reused 42 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxwhU0xHtsdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GitHub Colab directory\n",
        "# Directories for files\n",
        "holmes_file = '/content/DL_Assg2/holmes.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUg9FIRJ2vOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ce7750a1-385d-4a43-b419-e7551c928523"
      },
      "source": [
        "#Google drive model upload/save storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path='/content/drive/My Drive/Colab Notebooks/DL_Assg2_Models/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BXl__WTIzDw",
        "colab_type": "text"
      },
      "source": [
        "## Step 1 – Data Loading and Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApFnQPRIzDw",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edsqbjtrIzDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "617de445-180e-4d0d-a4d0-df01729b635c"
      },
      "source": [
        "# read in the text file, transforming everything to lower case\n",
        "text = open(holmes_file).read().lower()\n",
        "print('The original text has ' + str(len(text)) + ' characters.\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The original text has 562422 characters.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga5JfFmVIzDy",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Data Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFCH3DmGIzDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "c0d4e660-9458-452b-e56f-d1ee96801425"
      },
      "source": [
        "### print out the first 1000 characters of the raw text to get a sense of what characters to remove\n",
        "text[:2000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ufeffthe adventures of sherlock holmes by sir arthur conan doyle\\n\\n   i. a scandal in bohemia\\n  ii. the red-headed league\\n iii. a case of identity\\n  iv. the boscombe valley mystery\\n   v. the five orange pips\\n  vi. the man with the twisted lip\\n vii. the adventure of the blue carbuncle\\nviii. the adventure of the speckled band\\n  ix. the adventure of the engineer's thumb\\n   x. the adventure of the noble bachelor\\n  xi. the adventure of the beryl coronet\\n xii. the adventure of the copper beeches\\n\\n\\nadventure i. a scandal in bohemia\\n\\ni.\\n\\nto sherlock holmes she is always the woman. i have seldom heard\\nhim mention her under any other name. in his eyes she eclipses\\nand predominates the whole of her sex. it was not that he felt\\nany emotion akin to love for irene adler. all emotions, and that\\none particularly, were abhorrent to his cold, precise but\\nadmirably balanced mind. he was, i take it, the most perfect\\nreasoning and observing machine that the world has seen, but as a\\nlover he would have placed himself in a false position. he never\\nspoke of the softer passions, save with a gibe and a sneer. they\\nwere admirable things for the observer--excellent for drawing the\\nveil from men's motives and actions. but for the trained reasoner\\nto admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a distracting factor which\\nmight throw a doubt upon all his mental results. grit in a\\nsensitive instrument, or a crack in one of his own high-power\\nlenses, would not be more disturbing than a strong emotion in a\\nnature such as his. and yet there was but one woman to him, and\\nthat woman was the late irene adler, of dubious and questionable\\nmemory.\\n\\ni had seen little of holmes lately. my marriage had drifted us\\naway from each other. my own complete happiness, and the\\nhome-centred interests which rise up around the man who first\\nfinds himself master of his own establishment, were sufficient to\\nabsorb all my attention, while holmes, who loathed every form of\\nsociety \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGWz3AusIzD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8587e9f0-4142-414f-d1f1-eef87ec91391"
      },
      "source": [
        "# remove all '\\n' and '\\r' from text\n",
        "text = text.replace('\\n','') \n",
        "text = text.replace('\\r','')\n",
        "\n",
        "print(text[:2000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿the adventures of sherlock holmes by sir arthur conan doyle   i. a scandal in bohemia  ii. the red-headed league iii. a case of identity  iv. the boscombe valley mystery   v. the five orange pips  vi. the man with the twisted lip vii. the adventure of the blue carbuncleviii. the adventure of the speckled band  ix. the adventure of the engineer's thumb   x. the adventure of the noble bachelor  xi. the adventure of the beryl coronet xii. the adventure of the copper beechesadventure i. a scandal in bohemiai.to sherlock holmes she is always the woman. i have seldom heardhim mention her under any other name. in his eyes she eclipsesand predominates the whole of her sex. it was not that he feltany emotion akin to love for irene adler. all emotions, and thatone particularly, were abhorrent to his cold, precise butadmirably balanced mind. he was, i take it, the most perfectreasoning and observing machine that the world has seen, but as alover he would have placed himself in a false position. he neverspoke of the softer passions, save with a gibe and a sneer. theywere admirable things for the observer--excellent for drawing theveil from men's motives and actions. but for the trained reasonerto admit such intrusions into his own delicate and finelyadjusted temperament was to introduce a distracting factor whichmight throw a doubt upon all his mental results. grit in asensitive instrument, or a crack in one of his own high-powerlenses, would not be more disturbing than a strong emotion in anature such as his. and yet there was but one woman to him, andthat woman was the late irene adler, of dubious and questionablememory.i had seen little of holmes lately. my marriage had drifted usaway from each other. my own complete happiness, and thehome-centred interests which rise up around the man who firstfinds himself master of his own establishment, were sufficient toabsorb all my attention, while holmes, who loathed every form ofsociety with his whole bohemian soul, remained in our\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39LI1iTOIzD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a function 'clean_text' to clean text so that only the following letters and punctation remain\n",
        "def clean_text(text):\n",
        "    punctuation = ['!', ',', '.', ':', ';', '?', '-', \"'\",' ']\n",
        "    letters='abcdefghijklmnopqrstuvwxyz'\n",
        "    \n",
        "    # Enter your code here:\n",
        "    clean_text=''\n",
        "\n",
        "    for i in text:\n",
        "      if i in punctuation or i in letters:\n",
        "        clean_text+=i\n",
        "\n",
        "    return clean_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsGJWaVnIzD5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "93fe8a95-e16b-4337-b766-43505cb81e45"
      },
      "source": [
        "# clean data using clean_text function\n",
        "text = clean_text(text)\n",
        "text[:2000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the adventures of sherlock holmes by sir arthur conan doyle   i. a scandal in bohemia  ii. the red-headed league iii. a case of identity  iv. the boscombe valley mystery   v. the five orange pips  vi. the man with the twisted lip vii. the adventure of the blue carbuncleviii. the adventure of the speckled band  ix. the adventure of the engineer's thumb   x. the adventure of the noble bachelor  xi. the adventure of the beryl coronet xii. the adventure of the copper beechesadventure i. a scandal in bohemiai.to sherlock holmes she is always the woman. i have seldom heardhim mention her under any other name. in his eyes she eclipsesand predominates the whole of her sex. it was not that he feltany emotion akin to love for irene adler. all emotions, and thatone particularly, were abhorrent to his cold, precise butadmirably balanced mind. he was, i take it, the most perfectreasoning and observing machine that the world has seen, but as alover he would have placed himself in a false position. he neverspoke of the softer passions, save with a gibe and a sneer. theywere admirable things for the observer--excellent for drawing theveil from men's motives and actions. but for the trained reasonerto admit such intrusions into his own delicate and finelyadjusted temperament was to introduce a distracting factor whichmight throw a doubt upon all his mental results. grit in asensitive instrument, or a crack in one of his own high-powerlenses, would not be more disturbing than a strong emotion in anature such as his. and yet there was but one woman to him, andthat woman was the late irene adler, of dubious and questionablememory.i had seen little of holmes lately. my marriage had drifted usaway from each other. my own complete happiness, and thehome-centred interests which rise up around the man who firstfinds himself master of his own establishment, were sufficient toabsorb all my attention, while holmes, who loathed every form ofsociety with his whole bohemian soul, remained in our \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etvZzKpxIzD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "148bb033-bb0b-4a3f-c957-7768ae6a77bd"
      },
      "source": [
        "# count the number of unique characters in the text\n",
        "chars = sorted(list(set(text)))\n",
        "\n",
        "# print some of the text, as well as statistics\n",
        "print (\"This document has \" +  str(len(text)) + \" total number of characters.\")\n",
        "print (\"This document has \" +  str(len(chars)) + \" unique characters.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This document has 544340 total number of characters.\n",
            "This document has 35 unique characters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31dPYdLxIzD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a function 'generate_text_io' to generate text inputs based on window_size and the corresponding labels\n",
        "def generate_text_io(text, window_size):\n",
        "    inputs = [] # store inputs\n",
        "    labels = [] # stores label\n",
        "    \n",
        "    # Enter your code here:\n",
        "    for i in range(0, len(text)-window_size):\n",
        "      inputs.append(text[i:i+window_size])\n",
        "      labels.append(text[i+window_size])\n",
        "    \n",
        "    print(\"Num of Sequences: \",len(inputs))\n",
        "    print(inputs)\n",
        "    return inputs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj42ZA8tIzD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this dictionary is a function mapping each unique character to a unique integer\n",
        "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
        "\n",
        "# this dictionary is a function mapping each unique integer back to a unique character\n",
        "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrqDoltLIzEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# create a function 'encode_io_pairs' to perform one-hot encoding of inputs and labels\n",
        "def encode_io_pairs(text,window_size): # window_size determines # of characters in each input\n",
        "    \n",
        "    # Enter your code here:\n",
        "    inputs, labels = generate_text_io(text, window_size)\n",
        "\n",
        "\n",
        "    # Next, one-hot encode the characters into binary arrays.\n",
        "    print('Vectorization...')\n",
        "    x = np.zeros((len(inputs), window_size, len(chars)), dtype=np.bool)\n",
        "    y = np.zeros((len(inputs), len(chars)), dtype=np.bool)\n",
        "    for i, sentence in enumerate(inputs):\n",
        "        for t, char in enumerate(sentence):\n",
        "            x[i, t, chars_to_indices[char]] = 1\n",
        "        y[i, chars_to_indices[labels[i]]] = 1\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeeuHDQLIzEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "39747a60-90e4-461c-dfc7-c53ea74b88cd"
      },
      "source": [
        "# perform one-hot encoding of inputs and labels\n",
        "window_size = 100\n",
        "X, y = encode_io_pairs(text, window_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of Sequences:  544240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pBlfPVcIzEE",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Splitting Dataset into Inputs (X) and Labels (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ob1YhtcIzEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b64c2093-ff20-4f88-9e7a-ff9eb431741a"
      },
      "source": [
        "# Note: You may choose to perform this step before encoding the data (step 1.2).\n",
        "# Enter your code here:\n",
        "print (y.shape)\n",
        "print (X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(544240, 35)\n",
            "(544240, 100, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMsx4elxIzEG",
        "colab_type": "text"
      },
      "source": [
        "## Step 2 – Develop a Character Generator Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iFmcWR9hzqbX"
      },
      "source": [
        "### Model #1 (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TC8D9pqRzqbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d01129a8-089b-4e92-81f2-3a67d2571cd0"
      },
      "source": [
        "# Build the Model\n",
        "# Enter your code here:\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(window_size, len(chars)))) #multiclass single label classification\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               83968     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 35)                4515      \n",
            "=================================================================\n",
            "Total params: 88,483\n",
            "Trainable params: 88,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a9DrHBgEzqbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "2fef71d5-6886-4a09-db38-a060d441c934"
      },
      "source": [
        "# Train the Model\n",
        "# Enter your code here:\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['acc'])\n",
        "\n",
        "history = model.fit(X, y,\n",
        "                    epochs=15,\n",
        "                    batch_size=128) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "4252/4252 [==============================] - 104s 24ms/step - loss: 1.7489 - acc: 0.4853\n",
            "Epoch 2/15\n",
            "4252/4252 [==============================] - 104s 24ms/step - loss: 1.5314 - acc: 0.5466\n",
            "Epoch 3/15\n",
            "4252/4252 [==============================] - 103s 24ms/step - loss: 1.4809 - acc: 0.5598\n",
            "Epoch 4/15\n",
            "4252/4252 [==============================] - 104s 24ms/step - loss: 1.4549 - acc: 0.5672\n",
            "Epoch 5/15\n",
            "4252/4252 [==============================] - 105s 25ms/step - loss: 1.4369 - acc: 0.5714\n",
            "Epoch 6/15\n",
            "4252/4252 [==============================] - 105s 25ms/step - loss: 1.4230 - acc: 0.5754\n",
            "Epoch 7/15\n",
            "4252/4252 [==============================] - 104s 24ms/step - loss: 1.4128 - acc: 0.5785\n",
            "Epoch 8/15\n",
            "4252/4252 [==============================] - 104s 25ms/step - loss: 1.4052 - acc: 0.5802\n",
            "Epoch 9/15\n",
            "4252/4252 [==============================] - 104s 24ms/step - loss: 1.3983 - acc: 0.5824\n",
            "Epoch 10/15\n",
            "4252/4252 [==============================] - 104s 24ms/step - loss: 1.3928 - acc: 0.5839\n",
            "Epoch 11/15\n",
            "4252/4252 [==============================] - 105s 25ms/step - loss: 1.3879 - acc: 0.5849\n",
            "Epoch 12/15\n",
            "4252/4252 [==============================] - 104s 25ms/step - loss: 1.3842 - acc: 0.5858\n",
            "Epoch 13/15\n",
            "4252/4252 [==============================] - 104s 24ms/step - loss: 1.3806 - acc: 0.5871\n",
            "Epoch 14/15\n",
            "4252/4252 [==============================] - 105s 25ms/step - loss: 1.3773 - acc: 0.5878\n",
            "Epoch 15/15\n",
            "4252/4252 [==============================] - 103s 24ms/step - loss: 1.3734 - acc: 0.5891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O8cgd5Tczqbh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "c28b4a78-532e-4966-83a3-43ff22db64ad"
      },
      "source": [
        "# Plot the Training and Validation Accuracy & Loss Scores\n",
        "# Enter your code here:\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o1ySeN_zzqbj",
        "colab": {}
      },
      "source": [
        "# Save the Model\n",
        "model.save(model_path+'chgen_model_2.h5')\n",
        "model.save('chgen_model_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH8_cts-IzEN",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluation [chgen_model_1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxg-RvelIzEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "\n",
        "#model.load_weights('chgen_model_best.h5')\n",
        "\n",
        "model = models.load_model(model_path+'chgen_model_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBcMOTCfIzEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f631ec4a-3c36-46f2-f745-51a0b3c82c06"
      },
      "source": [
        "# takes the user input\n",
        "\n",
        "#Oh's third victim was hawker stall owner Ng Phek Huay, whom he stole from on Sept 9, 2019.  While Madam Ng, 71, was waiting for her turn to see the doctor at Queenstown Polyclinic, he stole money from her handbag.  He then offered her zopiclone and convinced her that she had to take it before her medical check-up.  Thinking that Oh was one of the polyclinic staff, Madam Ng took the drug and became drowsy.  He then took from her a gold-coloured bracelet which she was wearing and took her out of the polyclinic.  Oh then got a taxi to take Madam Ng to NUH, as she was losing consciousness.  On Friday, District Judge Gwee backdated Oh's sentence to Sept 12 last year, when he was first remanded.\n",
        "\n",
        "#text_input = np.array([input()])\n",
        "text_input = clean_text(input().lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i love going to the park, especially when it is windy or sunny. every satruday i go to the park after buying ice cream.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je5VZdwRIzEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6a544286-8b41-4a3d-d900-a8e6071adbc8"
      },
      "source": [
        "# one-hot encode the user input\n",
        "# Enter your code here:\n",
        "new_window_size = 5\n",
        "\n",
        "X, y = encode_io_pairs(text_input, new_window_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of Sequences:  114\n",
            "['i lov', ' love', 'love ', 'ove g', 've go', 'e goi', ' goin', 'going', 'oing ', 'ing t', 'ng to', 'g to ', ' to t', 'to th', 'o the', ' the ', 'the p', 'he pa', 'e par', ' park', 'park,', 'ark, ', 'rk, e', 'k, es', ', esp', ' espe', 'espec', 'speci', 'pecia', 'ecial', 'ciall', 'ially', 'ally ', 'lly w', 'ly wh', 'y whe', ' when', 'when ', 'hen i', 'en it', 'n it ', ' it i', 'it is', 't is ', ' is w', 'is wi', 's win', ' wind', 'windy', 'indy ', 'ndy o', 'dy or', 'y or ', ' or s', 'or su', 'r sun', ' sunn', 'sunny', 'unny.', 'nny. ', 'ny. e', 'y. ev', '. eve', ' ever', 'every', 'very ', 'ery s', 'ry sa', 'y sat', ' satr', 'satru', 'atrud', 'truda', 'ruday', 'uday ', 'day i', 'ay i ', 'y i g', ' i go', 'i go ', ' go t', 'go to', 'o to ', ' to t', 'to th', 'o the', ' the ', 'the p', 'he pa', 'e par', ' park', 'park ', 'ark a', 'rk af', 'k aft', ' afte', 'after', 'fter ', 'ter b', 'er bu', 'r buy', ' buyi', 'buyin', 'uying', 'ying ', 'ing i', 'ng ic', 'g ice', ' ice ', 'ice c', 'ce cr', 'e cre', ' crea', 'cream']\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecucq2ljIzES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "e5ba20c3-1104-4d82-90cf-cd94be363f27"
      },
      "source": [
        "# show the model output using predict function\n",
        "# Enter your code here:\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "  \n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(X, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text_input) - new_window_size - 1)\n",
        "    generated_text = text_input[start_index: start_index + new_window_size]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ temperature:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # We generate 400 characters\n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, new_window_size, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"lstm_1_input:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 5, 35).\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1473 - acc: 0.3947\n",
            "--- Generating with seed: \" to t\"\n",
            "------ temperature: 0.2\n",
            " to tWARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"lstm_1_input:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 5, 35).\n",
            "he could to the possible to the stone of the stone and start that her land a great then heard to the stone front of the could before man which was a few her heard to the could to the could before man which offere which was a man which was a stall that her lady and stand a staff the stone and stood and sentention which was a man which was the stone of the stone to the could to the could to the coul\n",
            "------ temperature: 0.5\n",
            " could as madam took he was a man her heard so wearing. then some polsceremond to seen this manwas here. then way street-hand-convinich possible to the done to record to the possible restrade, he was not to me to her head what wearing with the done and day at the breakfor that then story of the great as to the time to the still that i could to go polyclips from to the seemed and having had a grey sept \n",
            "------ temperature: 1.0\n",
            "sept the coadter cropance. inly on the seeusto rushed to vilwwence the convictirly as het-expense then header in his remans-grin still as point. the pept whose explainly oochokey seventchark at they in then youet one fore opistodadling stalf-hrixt sister office who oad betweenctiem queeniony rocked in eut of it fellad which was as hear briting, sharp first for he shalf framedois, had stom of her to him\n",
            "------ temperature: 1.2\n",
            "o him.you heols mind on you clodie.i am ofger, rather coac. right the charc france wilswerploy notostreres' put at evidunebrasing a nanimpatwild who has next up.oh, said onex, mccarturned cheir.heppody to girlar. in him whichas i had tlee.holmes. one to lookness. when idbarring heaving upwasives fourief.becautit to admisal vurbingssww, go. havereaysgreed's"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " becamenestpresside be stuwk her azier's gently\n",
            "epoch 2\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7126 - acc: 0.4649\n",
            "--- Generating with seed: \"to th\"\n",
            "------ temperature: 0.2\n",
            "to the possible to the back to the poster to the could stook that her lady to the could to the could to the could to the passion the could to the stone and seemed to the counted to the possible to the possible to the possible to the possible and seen to the stone was a stall that her heard to the passion the could stoo secretuin which was a stair was a stake the could to the passion the possible to the\n",
            "------ temperature: 0.5\n",
            "o the charge pain, and clear of the paper facty, expection dressed the story man the take matteress--then hand off the find to the mad on our from to her last was put that her from to be sepolitic as to company as she had the the promister was the postly then great her last he was neat her lady to the stone which while to the chair, said--the passical. it were seeing which wearing he new on a hand a st\n",
            "------ temperature: 1.0\n",
            " a statderwarder though. goldication thishealop, he seemed by the puncine, holmes the may beaution. so weapon, do. the furthis watthe accouuting, a pairange lady very acrip offenders heant he saive vaca, beaution beec? the circuminatewfagary, but to finding uppressent to other build her to the done plence, he couuse oyey, has stagger iimmanigle colution, hcouped to convincounder men, of the backdant he\n",
            "------ temperature: 1.2\n",
            "nt hereclockencedly to un. passed a lone vature or what i had yescehancemeritichactifial other from to man which hand,swanderunudd's. was possible is a polycenty in which richalperson empty, wearing which yello tedler's wanted to, as ensiilm behfatam to the propoling, gon they cross bard people he had havpencale beecjqy toot, of the lay being right, taffated. on found out copper whole at we county's co\n",
            "epoch 3\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4651 - acc: 0.5263\n",
            "--- Generating with seed: \"ially\"\n",
            "------ temperature: 0.2\n",
            "ially which was the passag, and sentention which was a station the stone and seven to the could before man which was a man which was a good stook the counted the passion the could to the would to the story a stake a stake thing to the count out of the counted the could to the possible to the possible to the story stall the counten this stake the possible to the possible to the stone and senterest to th\n",
            "------ temperature: 0.5\n",
            "to the could dr. when in the could to the got of the looking and hard, but in the promistreet in the passion from to the staff the stone to the passed the park and her walk of the convince to the front of the close of the stone card one is a hard first to the park her client to me to the beece should which oolshould it is that to the would front of the stop and a gows on succeedes. when hour which whic\n",
            "------ temperature: 1.0\n",
            " which were over manbank a when tried before lord conscloadow abrug that at her noticetalled-inquary lady neating open sower, but knew with hung wade then what joking ! occloudon off for a large statastendly and the bottom on cocked him your of she master. if the call to the polscip. mr. rud of the police, will betwe looking, two which was we walked before years. then polices wever which only would whi\n",
            "------ temperature: 1.2\n",
            "d whitchedowe the treater,put in strangel ogevy outwaitin upsnamone which ot was still from huar old very paliatlewhesteff what master ideahy, you, procesidas convicton-laddry-brown ile to seated a atthe filler off with allow.person. toicance aa dear, advemmnewan miss to shuttle convictility, holmes harfwan'st ce'shes to himknop, richinany.in they . by then manyly pime, he was plucked! the neithkering \n",
            "epoch 4\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2787 - acc: 0.6140\n",
            "--- Generating with seed: \" park\"\n",
            "------ temperature: 0.2\n",
            " park the chair was a stake the park that the counting that in the county he was the could to the county were and had seven this was a good when her her thing to the possible to the possible to the story and stook the park and the could becamere story and seven this consny other which was a street to the possible to the park the park of the park the park to the park the park that i had secretsin steps \n",
            "------ temperature: 0.5\n",
            "teps which was a good at the passagber weekly at the passed the back to him. i had a loss that her man's stole in the chark which was cord hand before client her leaningone as a last out of the possible to them it, then last was a find the stone acrossest to me, was her lady of his child when hand, when in the calling was on it was day, i am nkery work and was have her less less which occupationed and \n",
            "------ temperature: 1.0\n",
            " and from side, to entening,for myelfather was led from then key hundrew the convincincillar limence of me stole to the dark her loven no wondert of the gently from cheekss, he was was say's hasteio, taking to reasone shaking. no seck up. she had much escerture, from an ect many, muspehanued it. you her clienture ofecoaning to take thjeer upon esking will braced to the matterd? then story, back was eve\n",
            "------ temperature: 1.2\n",
            "s everysenting. crle'sthat pro't clearlentlem,mccascoad waffe. at at laidarten one good bitialam nrreq, skeypyber one scoulirat. i asked our money hear-toum. ygapstory letter nature prsshill warkshin it. i remanallagged that man anyprivatistam becamere this. he colume. he cry busher charkvimly pur jumber for mr. holmes agglish were light laid if youiniebeg andojadde--two livesotag! while in a heard to \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZQOsbn2V01Yz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "73d77b41-ffff-4518-b88f-1c6f2b4914f0"
      },
      "source": [
        "model.fit(X, y, batch_size=128, epochs=1)\n",
        "temperature = 0.2\n",
        "\n",
        "text_ls = [\"dogs are grea\", \"please ente\", \"what a sigh\", \"edge of the worl\", \"would you please hurr\"]\n",
        "\n",
        "print('------ temperature:', temperature)\n",
        "print(\"Prediction: \")\n",
        "for i in text_ls:\n",
        "  sys.stdout.write(i)\n",
        "\n",
        "  # We generate 400 characters\n",
        "  # for i in range(400):\n",
        "  sampled = np.zeros((1, len(i), len(chars)))\n",
        "  for t, char in enumerate(i):\n",
        "      sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "  preds = model.predict(sampled, verbose=0)[0]\n",
        "  next_index = sample(preds, temperature)\n",
        "  next_char = chars[next_index]\n",
        "\n",
        "  sys.stdout.write(next_char)\n",
        "  sys.stdout.flush()\n",
        "  print()\n",
        "\n",
        "\n",
        "text_input = input(\"Enter sentence to predict next character: \\n\")\n",
        "print(\"Predicting user input... \\n\")\n",
        "sys.stdout.write(text_input)\n",
        "\n",
        "sampled = np.zeros((1, len(text_input), len(chars)))\n",
        "for t, char in enumerate(text_input):\n",
        "    sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "preds = model.predict(sampled, verbose=0)[0]\n",
        "next_index = sample(preds, temperature)\n",
        "next_char = chars[next_index]\n",
        "\n",
        "text_input += next_char\n",
        "text_input = text_input[1:]\n",
        "\n",
        "\n",
        "sys.stdout.write(next_char)\n",
        "sys.stdout.flush()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0243 - acc: 0.6930\n",
            "------ temperature: 0.2\n",
            "Prediction: \n",
            "dogs are great\n",
            "please enter\n",
            "what a sight\n",
            "edge of the world\n",
            "would you please hurry\n",
            "Enter sentence to predict next character: \n",
            "i am so happ\n",
            "Predicting user input... \n",
            "\n",
            "i am so happy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5x-28iFusCiw"
      },
      "source": [
        "#### Evaluation [chgen_model_1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4rMA1ribsCiz",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "\n",
        "#model.load_weights('chgen_model_best.h5')\n",
        "\n",
        "model = models.load_model(model_path+'chgen_model_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "USpaXKbZsCi3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6ddb0f35-5770-4a36-dfdb-575ce067cd91"
      },
      "source": [
        "# takes the user input\n",
        "\n",
        "#Oh's third victim was hawker stall owner Ng Phek Huay, whom he stole from on Sept 9, 2019.  While Madam Ng, 71, was waiting for her turn to see the doctor at Queenstown Polyclinic, he stole money from her handbag.  He then offered her zopiclone and convinced her that she had to take it before her medical check-up.  Thinking that Oh was one of the polyclinic staff, Madam Ng took the drug and became drowsy.  He then took from her a gold-coloured bracelet which she was wearing and took her out of the polyclinic.  Oh then got a taxi to take Madam Ng to NUH, as she was losing consciousness.  On Friday, District Judge Gwee backdated Oh's sentence to Sept 12 last year, when he was first remanded.\n",
        "\n",
        "#text_input = np.array([input()])\n",
        "text_input = clean_text(input().lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oh's third victim was hawker stall owner Ng Phek Huay, whom he stole from on Sept 9, 2019.  While Madam Ng, 71, was waiting for her turn to see the doctor at Queenstown Polyclinic, he stole money from her handbag.  He then offered her zopiclone and convinced her that she had to take it before her medical check-up.  Thinking that Oh was one of the polyclinic staff, Madam Ng took the drug and became drowsy.  He then took from her a gold-coloured bracelet which she was wearing and took her out of the polyclinic.  Oh then got a taxi to take Madam Ng to NUH, as she was losing consciousness.  On Friday, District Judge Gwee backdated Oh's sentence to Sept 12 last year, when he was first remanded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "76ZHGlFpsCi5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "2273f1a2-3e3c-47f1-8ab1-35537ef5a10a"
      },
      "source": [
        "# one-hot encode the user input\n",
        "# Enter your code here:\n",
        "new_window_size = 10\n",
        "\n",
        "X, y = encode_io_pairs(text_input, new_window_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of Sequences:  679\n",
            "[\"oh's third\", \"h's third \", \"'s third v\", 's third vi', ' third vic', 'third vict', 'hird victi', 'ird victim', 'rd victim ', 'd victim w', ' victim wa', 'victim was', 'ictim was ', 'ctim was h', 'tim was ha', 'im was haw', 'm was hawk', ' was hawke', 'was hawker', 'as hawker ', 's hawker s', ' hawker st', 'hawker sta', 'awker stal', 'wker stall', 'ker stall ', 'er stall o', 'r stall ow', ' stall own', 'stall owne', 'tall owner', 'all owner ', 'll owner n', 'l owner ng', ' owner ng ', 'owner ng p', 'wner ng ph', 'ner ng phe', 'er ng phek', 'r ng phek ', ' ng phek h', 'ng phek hu', 'g phek hua', ' phek huay', 'phek huay,', 'hek huay, ', 'ek huay, w', 'k huay, wh', ' huay, who', 'huay, whom', 'uay, whom ', 'ay, whom h', 'y, whom he', ', whom he ', ' whom he s', 'whom he st', 'hom he sto', 'om he stol', 'm he stole', ' he stole ', 'he stole f', 'e stole fr', ' stole fro', 'stole from', 'tole from ', 'ole from o', 'le from on', 'e from on ', ' from on s', 'from on se', 'rom on sep', 'om on sept', 'm on sept ', ' on sept ,', 'on sept , ', 'n sept , .', ' sept , . ', 'sept , .  ', 'ept , .  w', 'pt , .  wh', 't , .  whi', ' , .  whil', ', .  while', ' .  while ', '.  while m', '  while ma', ' while mad', 'while mada', 'hile madam', 'ile madam ', 'le madam n', 'e madam ng', ' madam ng,', 'madam ng, ', 'adam ng, ,', 'dam ng, , ', 'am ng, , w', 'm ng, , wa', ' ng, , was', 'ng, , was ', 'g, , was w', ', , was wa', ' , was wai', ', was wait', ' was waiti', 'was waitin', 'as waiting', 's waiting ', ' waiting f', 'waiting fo', 'aiting for', 'iting for ', 'ting for h', 'ing for he', 'ng for her', 'g for her ', ' for her t', 'for her tu', 'or her tur', 'r her turn', ' her turn ', 'her turn t', 'er turn to', 'r turn to ', ' turn to s', 'turn to se', 'urn to see', 'rn to see ', 'n to see t', ' to see th', 'to see the', 'o see the ', ' see the d', 'see the do', 'ee the doc', 'e the doct', ' the docto', 'the doctor', 'he doctor ', 'e doctor a', ' doctor at', 'doctor at ', 'octor at q', 'ctor at qu', 'tor at que', 'or at quee', 'r at queen', ' at queens', 'at queenst', 't queensto', ' queenstow', 'queenstown', 'ueenstown ', 'eenstown p', 'enstown po', 'nstown pol', 'stown poly', 'town polyc', 'own polycl', 'wn polycli', 'n polyclin', ' polyclini', 'polyclinic', 'olyclinic,', 'lyclinic, ', 'yclinic, h', 'clinic, he', 'linic, he ', 'inic, he s', 'nic, he st', 'ic, he sto', 'c, he stol', ', he stole', ' he stole ', 'he stole m', 'e stole mo', ' stole mon', 'stole mone', 'tole money', 'ole money ', 'le money f', 'e money fr', ' money fro', 'money from', 'oney from ', 'ney from h', 'ey from he', 'y from her', ' from her ', 'from her h', 'rom her ha', 'om her han', 'm her hand', ' her handb', 'her handba', 'er handbag', 'r handbag.', ' handbag. ', 'handbag.  ', 'andbag.  h', 'ndbag.  he', 'dbag.  he ', 'bag.  he t', 'ag.  he th', 'g.  he the', '.  he then', '  he then ', ' he then o', 'he then of', 'e then off', ' then offe', 'then offer', 'hen offere', 'en offered', 'n offered ', ' offered h', 'offered he', 'ffered her', 'fered her ', 'ered her z', 'red her zo', 'ed her zop', 'd her zopi', ' her zopic', 'her zopicl', 'er zopiclo', 'r zopiclon', ' zopiclone', 'zopiclone ', 'opiclone a', 'piclone an', 'iclone and', 'clone and ', 'lone and c', 'one and co', 'ne and con', 'e and conv', ' and convi', 'and convin', 'nd convinc', 'd convince', ' convinced', 'convinced ', 'onvinced h', 'nvinced he', 'vinced her', 'inced her ', 'nced her t', 'ced her th', 'ed her tha', 'd her that', ' her that ', 'her that s', 'er that sh', 'r that she', ' that she ', 'that she h', 'hat she ha', 'at she had', 't she had ', ' she had t', 'she had to', 'he had to ', 'e had to t', ' had to ta', 'had to tak', 'ad to take', 'd to take ', ' to take i', 'to take it', 'o take it ', ' take it b', 'take it be', 'ake it bef', 'ke it befo', 'e it befor', ' it before', 'it before ', 't before h', ' before he', 'before her', 'efore her ', 'fore her m', 'ore her me', 're her med', 'e her medi', ' her medic', 'her medica', 'er medical', 'r medical ', ' medical c', 'medical ch', 'edical che', 'dical chec', 'ical check', 'cal check-', 'al check-u', 'l check-up', ' check-up.', 'check-up. ', 'heck-up.  ', 'eck-up.  t', 'ck-up.  th', 'k-up.  thi', '-up.  thin', 'up.  think', 'p.  thinki', '.  thinkin', '  thinking', ' thinking ', 'thinking t', 'hinking th', 'inking tha', 'nking that', 'king that ', 'ing that o', 'ng that oh', 'g that oh ', ' that oh w', 'that oh wa', 'hat oh was', 'at oh was ', 't oh was o', ' oh was on', 'oh was one', 'h was one ', ' was one o', 'was one of', 'as one of ', 's one of t', ' one of th', 'one of the', 'ne of the ', 'e of the p', ' of the po', 'of the pol', 'f the poly', ' the polyc', 'the polycl', 'he polycli', 'e polyclin', ' polyclini', 'polyclinic', 'olyclinic ', 'lyclinic s', 'yclinic st', 'clinic sta', 'linic staf', 'inic staff', 'nic staff,', 'ic staff, ', 'c staff, m', ' staff, ma', 'staff, mad', 'taff, mada', 'aff, madam', 'ff, madam ', 'f, madam n', ', madam ng', ' madam ng ', 'madam ng t', 'adam ng to', 'dam ng too', 'am ng took', 'm ng took ', ' ng took t', 'ng took th', 'g took the', ' took the ', 'took the d', 'ook the dr', 'ok the dru', 'k the drug', ' the drug ', 'the drug a', 'he drug an', 'e drug and', ' drug and ', 'drug and b', 'rug and be', 'ug and bec', 'g and beca', ' and becam', 'and became', 'nd became ', 'd became d', ' became dr', 'became dro', 'ecame drow', 'came drows', 'ame drowsy', 'me drowsy.', 'e drowsy. ', ' drowsy.  ', 'drowsy.  h', 'rowsy.  he', 'owsy.  he ', 'wsy.  he t', 'sy.  he th', 'y.  he the', '.  he then', '  he then ', ' he then t', 'he then to', 'e then too', ' then took', 'then took ', 'hen took f', 'en took fr', 'n took fro', ' took from', 'took from ', 'ook from h', 'ok from he', 'k from her', ' from her ', 'from her a', 'rom her a ', 'om her a g', 'm her a go', ' her a gol', 'her a gold', 'er a gold-', 'r a gold-c', ' a gold-co', 'a gold-col', ' gold-colo', 'gold-colou', 'old-colour', 'ld-coloure', 'd-coloured', '-coloured ', 'coloured b', 'oloured br', 'loured bra', 'oured brac', 'ured brace', 'red bracel', 'ed bracele', 'd bracelet', ' bracelet ', 'bracelet w', 'racelet wh', 'acelet whi', 'celet whic', 'elet which', 'let which ', 'et which s', 't which sh', ' which she', 'which she ', 'hich she w', 'ich she wa', 'ch she was', 'h she was ', ' she was w', 'she was we', 'he was wea', 'e was wear', ' was weari', 'was wearin', 'as wearing', 's wearing ', ' wearing a', 'wearing an', 'earing and', 'aring and ', 'ring and t', 'ing and to', 'ng and too', 'g and took', ' and took ', 'and took h', 'nd took he', 'd took her', ' took her ', 'took her o', 'ook her ou', 'ok her out', 'k her out ', ' her out o', 'her out of', 'er out of ', 'r out of t', ' out of th', 'out of the', 'ut of the ', 't of the p', ' of the po', 'of the pol', 'f the poly', ' the polyc', 'the polycl', 'he polycli', 'e polyclin', ' polyclini', 'polyclinic', 'olyclinic.', 'lyclinic. ', 'yclinic.  ', 'clinic.  o', 'linic.  oh', 'inic.  oh ', 'nic.  oh t', 'ic.  oh th', 'c.  oh the', '.  oh then', '  oh then ', ' oh then g', 'oh then go', 'h then got', ' then got ', 'then got a', 'hen got a ', 'en got a t', 'n got a ta', ' got a tax', 'got a taxi', 'ot a taxi ', 't a taxi t', ' a taxi to', 'a taxi to ', ' taxi to t', 'taxi to ta', 'axi to tak', 'xi to take', 'i to take ', ' to take m', 'to take ma', 'o take mad', ' take mada', 'take madam', 'ake madam ', 'ke madam n', 'e madam ng', ' madam ng ', 'madam ng t', 'adam ng to', 'dam ng to ', 'am ng to n', 'm ng to nu', ' ng to nuh', 'ng to nuh,', 'g to nuh, ', ' to nuh, a', 'to nuh, as', 'o nuh, as ', ' nuh, as s', 'nuh, as sh', 'uh, as she', 'h, as she ', ', as she w', ' as she wa', 'as she was', 's she was ', ' she was l', 'she was lo', 'he was los', 'e was losi', ' was losin', 'was losing', 'as losing ', 's losing c', ' losing co', 'losing con', 'osing cons', 'sing consc', 'ing consci', 'ng conscio', 'g consciou', ' conscious', 'consciousn', 'onsciousne', 'nsciousnes', 'sciousness', 'ciousness.', 'iousness. ', 'ousness.  ', 'usness.  o', 'sness.  on', 'ness.  on ', 'ess.  on f', 'ss.  on fr', 's.  on fri', '.  on frid', '  on frida', ' on friday', 'on friday,', 'n friday, ', ' friday, d', 'friday, di', 'riday, dis', 'iday, dist', 'day, distr', 'ay, distri', 'y, distric', ', district', ' district ', 'district j', 'istrict ju', 'strict jud', 'trict judg', 'rict judge', 'ict judge ', 'ct judge g', 't judge gw', ' judge gwe', 'judge gwee', 'udge gwee ', 'dge gwee b', 'ge gwee ba', 'e gwee bac', ' gwee back', 'gwee backd', 'wee backda', 'ee backdat', 'e backdate', ' backdated', 'backdated ', 'ackdated o', 'ckdated oh', \"kdated oh'\", \"dated oh's\", \"ated oh's \", \"ted oh's s\", \"ed oh's se\", \"d oh's sen\", \" oh's sent\", \"oh's sente\", \"h's senten\", \"'s sentenc\", 's sentence', ' sentence ', 'sentence t', 'entence to', 'ntence to ', 'tence to s', 'ence to se', 'nce to sep', 'ce to sept', 'e to sept ', ' to sept  ', 'to sept  l', 'o sept  la', ' sept  las', 'sept  last', 'ept  last ', 'pt  last y', 't  last ye', '  last yea', ' last year', 'last year,', 'ast year, ', 'st year, w', 't year, wh', ' year, whe', 'year, when', 'ear, when ', 'ar, when h', 'r, when he', ', when he ', ' when he w', 'when he wa', 'hen he was', 'en he was ', 'n he was f', ' he was fi', 'he was fir', 'e was firs', ' was first', 'was first ', 'as first r', 's first re', ' first rem', 'first rema', 'irst reman', 'rst remand', 'st remande', 't remanded']\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pH4qXiG4sCi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "0acdf40b-bf4c-40e0-c31f-6cbe1b9591b9"
      },
      "source": [
        "# show the model output using predict function\n",
        "# Enter your code here:\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "  \n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(X, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text_input) - new_window_size - 1)\n",
        "    generated_text = text_input[start_index: start_index + new_window_size]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ temperature:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # We generate 400 characters\n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, new_window_size, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"lstm_1_input:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 10, 35).\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9633 - acc: 0.4580\n",
            "--- Generating with seed: \"from on se\"\n",
            "------ temperature: 0.2\n",
            "from on seWARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"lstm_1_input:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 10, 35).\n",
            "arch of the matter to the house, and the corner to the lady of the state of the police that he was a street which he had not come of the other was a street of the traces to the coloured and an anger of the state of the police that the man who was a state of the state of the state of the state of the traces to the state to the coronet which he was a story was a passage of the state of the great one\n",
            "------ temperature: 0.5\n",
            " great one of the state upon him where i was morning and seen to the miss hand so have some traces. he had let the death and the writing, he said, when he had been seen in an alshy he was as her way and leave the gaster had have seen to the age, which he had seen that the coronet, i saw her way of the room of the mind which he dreadwear man which mind here is her street-face of the room and seemed to the ot\n",
            "------ temperature: 1.0\n",
            " to the other, spect some  rather be, it was heir for the one rooms when he have huswartetil,for him of his receads.'indertime down be-feathe"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "r her bobleacracy. i amrrousant wasphoised,' said he.sharpened upon the requine and begon t monthn bloting featurer of you. that against her roade. she had not his permision into the matter.! leoked your hands.  foar weeks. we are anyte fundenfully using at the raid fo\n",
            "------ temperature: 1.2\n",
            "he raid for there.there were, concelted anverouty seees brot-empty hat and here, upi reason inturk his own bittensweek, tah! as i wasalreadywrict. 'to open cwebego lasclik that.i know thempforthy refuse twice tappear fromidbebb. which you despairing san him.it with than neitherly permiser-legger putted the daughtic obvious where. halfry, had been awjuccretoor every protme so i het was noting.breittyad uponw\n",
            "epoch 2\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5936 - acc: 0.5405\n",
            "--- Generating with seed: \"octor at q\"\n",
            "------ temperature: 0.2\n",
            "octor at quite and story and seemed to the police to the other was her street. i am a stranger was the state of the time, i have some state when he was at the lady of the time when he had a strong of the corner to the dark officed the state of the most street. i have the state out of the room was a companion of the state of the state to the traces to the state out of the first so was a street, and a man who\n",
            "------ temperature: 0.5\n",
            " a man who had not a securing office. it is in the drowling to the stair which you case it was a things of the house, he was new a man which was still for the leamed to come at the companion. and last a stair to let every left into the monvis to the time when he was a step from the until st. clair which were not to the funnityof the time when the presence her man, was was here he saw her head to the proberi\n",
            "------ temperature: 1.0\n",
            "he proberish hand, man. ifocling what be fronter. i should hro-coenly on right her safute at that an owerquesty of the other was umon's becessyproathowe ream after a conviesavity not estap andthe drive very in which upon it.then he had done sugtiber of baker man upon the  little sweel large play judger?oh, no kaulishor taking, as he stood onthe detcrase. gromflay mean on it. she spoke into acterenity so-tha\n",
            "------ temperature: 1.2\n",
            "ity so-thanly and irenethe dash ago, irebehaposmake uponthe neprome, eal she had yow, upon me tell your crimbrough either hit was done.there is matters almonicham any eyeshoff a wicked comfadered tick ruhe lefd it to makn.lysinalway curionit by it.but the flooring upon the pawr. , fromitethcy manish jowe musu makasbulm. on everythimp indo that the traedwhoot, so then imp and cauning to gicalithfucity, stand\n",
            "epoch 3\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3631 - acc: 0.5920\n",
            "--- Generating with seed: \"e backdate\"\n",
            "------ temperature: 0.2\n",
            "e backdated to the coroner and was a man which i have seemed to the state of the room when he was heard the state of the polyclinic from the stall on the state of the polyclinic and state to the state of the coroner that the state of the traces to the state on the polyclinic. then he was there was not on the word stook he was hand to the coronet to me to me that the state of the time when he had the state o\n",
            "------ temperature: 0.5\n",
            "he state out of the stair on the coroner of the stall police had the business as he was a solves of the coppers with a shoulder off the stall end of the attle havpn one of the streets that i had come to the strong the glad chair. and he had such a gold possible was a face stolk of the lady crime that the polyclinic door. i can so confinal of the other feeling of the polyclinic, then was a chasting to come a\n",
            "------ temperature: 1.0\n",
            " to come at not in ustic beker havancedfreen occupation up the legus on her persiou, in photograph to walk him that we may call a little street. this is before it lukest wife huster was immistance offime and groout you see that if then importancene,and what was discover attempt moment. a profession, di. the dreadflum to every race of her. it do nother calse pinci had chard had then mumth in sumeing knowlyth\n",
            "------ temperature: 1.2\n",
            "g knowlythin say from the hack ross. it is a snakiu that for the attrafm-ma's. at shadon. holmes flusl-cten but had under you strosed.glass silk by for our medical-thinged tig-forypridsaw seared,  steld, didventration and steppearforture uponthe grivingporsgle warfy lywit you are.then one.well, there harpyows on you, tell she dropper. then he hears bydon, holmes, said he, and made much of inwrithen was bill\n",
            "epoch 4\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1873 - acc: 0.6495\n",
            "--- Generating with seed: \"k-up.  thi\"\n",
            "------ temperature: 0.2\n",
            "k-up.  thinking that he was head to the polyclinic to the corner to the polyclinic of the time then he was from the polyclinic was a little staff to the polyclinic last stood her head to the polyclinic last hand off the stall was a stall was a stall of the polyclinic and the coroner to the polyclinic and seemed to the polyclinic and was a stall before the staff to the state of the polyclinic and seemed to t\n",
            "------ temperature: 0.5\n",
            "eemed to the other of the stall reasoned state of the very secret. i then put the other beganly to the dark hand with her way that we had a matter was enough the treech to the partic derection which i have a face of the other wonder about the words of the polyclinic. then he had had been to my stepfortunate and staked to the door, while he had all that we was then what even money that the stair, then we wer\n",
            "------ temperature: 1.0\n",
            "hen we were yeughtgract. it of neither bendopt. seem to time. at fromgate life at her that mimess she had facced heavingvning was to know a dayanmy neavier and chargeto thing. thin's have not some  was so was delay phofosed two ordar done.i rest you be a truck had ghilledodwility and offered my dear down drunkcastly took the time then she wassteed though tell hrden and map, he appears orweary to alloce, it \n",
            "------ temperature: 1.2\n",
            "lloce, it was claid anuble was penc an manan vich off the nought. frank he had guest was a stone oldupon you cleaned to see her llactioned ingall to cosil out from the chist corner's own, wuld chang at characte rinsally, a little i. havinest liting of the polyclinicity. and thinfoggition gim? i hesitan isloole rud charge barem heard to doce; it,reunxiam took  became thinh bag os to! then when i treet you re\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VL1No9ojXiqs"
      },
      "source": [
        "### Model #2 (GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kmhiLB7bXiqw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "88d38178-4724-45a2-fe40-6a45460c4abe"
      },
      "source": [
        "# Build the Model\n",
        "# Enter your code here:\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.GRU(256, input_shape=(window_size, len(chars)), return_sequences=True)) #multiclass single label classification\n",
        "model.add(layers.GRU(256))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 100, 256)          225024    \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 256)               394752    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 35)                8995      \n",
            "=================================================================\n",
            "Total params: 628,771\n",
            "Trainable params: 628,771\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n32nbsGkXiqz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "96222d85-ee0c-4997-c87f-45e46ff6d277"
      },
      "source": [
        "# Train the Model\n",
        "# Enter your code here:\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['acc'])\n",
        "\n",
        "history = model.fit(X, y,\n",
        "                    epochs=10,\n",
        "                    batch_size=128) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4252/4252 [==============================] - 114s 27ms/step - loss: 2.3538 - acc: 0.3219\n",
            "Epoch 2/10\n",
            "4252/4252 [==============================] - 115s 27ms/step - loss: 2.0286 - acc: 0.4053\n",
            "Epoch 3/10\n",
            "4252/4252 [==============================] - 115s 27ms/step - loss: 1.8838 - acc: 0.4456\n",
            "Epoch 4/10\n",
            "4252/4252 [==============================] - 115s 27ms/step - loss: 1.7878 - acc: 0.4720\n",
            "Epoch 5/10\n",
            "4252/4252 [==============================] - 115s 27ms/step - loss: 1.7137 - acc: 0.4934\n",
            "Epoch 6/10\n",
            "4252/4252 [==============================] - 115s 27ms/step - loss: 1.6529 - acc: 0.5113\n",
            "Epoch 7/10\n",
            "4252/4252 [==============================] - 115s 27ms/step - loss: 1.6018 - acc: 0.5265\n",
            "Epoch 8/10\n",
            "4252/4252 [==============================] - 115s 27ms/step - loss: 1.5586 - acc: 0.5390\n",
            "Epoch 9/10\n",
            "4252/4252 [==============================] - 115s 27ms/step - loss: 1.5214 - acc: 0.5499\n",
            "Epoch 10/10\n",
            "4252/4252 [==============================] - 115s 27ms/step - loss: 1.4895 - acc: 0.5584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b4SiTzTFXiq1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "192ace72-7d7e-4365-8eae-d58ef45cff3c"
      },
      "source": [
        "# Plot the Training and Validation Accuracy & Loss Scores\n",
        "# Enter your code here:\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "td-Hs3wRXiq2",
        "colab": {}
      },
      "source": [
        "# Save the Model\n",
        "model.save(model_path+'chgen_model_10.h5')\n",
        "model.save('chgen_model_10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kJvV5G_1ucGo"
      },
      "source": [
        "#### Evaluation [chgen_model_2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LMS6qEKFucGq",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "\n",
        "#model.load_weights('chgen_model_best.h5')\n",
        "\n",
        "model = models.load_model(model_path+'chgen_model_10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wFPh8No6ucGt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bd9ba88-c60a-40bc-bf77-f9398bda737b"
      },
      "source": [
        "# takes the user input\n",
        "\n",
        "#Oh's third victim was hawker stall owner Ng Phek Huay, whom he stole from on Sept 9, 2019.  While Madam Ng, 71, was waiting for her turn to see the doctor at Queenstown Polyclinic, he stole money from her handbag.  He then offered her zopiclone and convinced her that she had to take it before her medical check-up.  Thinking that Oh was one of the polyclinic staff, Madam Ng took the drug and became drowsy.  He then took from her a gold-coloured bracelet which she was wearing and took her out of the polyclinic.  Oh then got a taxi to take Madam Ng to NUH, as she was losing consciousness.  On Friday, District Judge Gwee backdated Oh's sentence to Sept 12 last year, when he was first remanded.\n",
        "\n",
        "#text_input = np.array([input()])\n",
        "text_input = clean_text(input().lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i love going to the park, especially when it is windy or sunny. every satruday i go to the park after buying ice cream.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1aW4pkLYucGw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d9e0cda2-d873-4c73-8e6b-0381d9769659"
      },
      "source": [
        "# one-hot encode the user input\n",
        "# Enter your code here:\n",
        "new_window_size = 5\n",
        "\n",
        "X, y = encode_io_pairs(text_input, new_window_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of Sequences:  114\n",
            "['i lov', ' love', 'love ', 'ove g', 've go', 'e goi', ' goin', 'going', 'oing ', 'ing t', 'ng to', 'g to ', ' to t', 'to th', 'o the', ' the ', 'the p', 'he pa', 'e par', ' park', 'park,', 'ark, ', 'rk, e', 'k, es', ', esp', ' espe', 'espec', 'speci', 'pecia', 'ecial', 'ciall', 'ially', 'ally ', 'lly w', 'ly wh', 'y whe', ' when', 'when ', 'hen i', 'en it', 'n it ', ' it i', 'it is', 't is ', ' is w', 'is wi', 's win', ' wind', 'windy', 'indy ', 'ndy o', 'dy or', 'y or ', ' or s', 'or su', 'r sun', ' sunn', 'sunny', 'unny.', 'nny. ', 'ny. e', 'y. ev', '. eve', ' ever', 'every', 'very ', 'ery s', 'ry sa', 'y sat', ' satr', 'satru', 'atrud', 'truda', 'ruday', 'uday ', 'day i', 'ay i ', 'y i g', ' i go', 'i go ', ' go t', 'go to', 'o to ', ' to t', 'to th', 'o the', ' the ', 'the p', 'he pa', 'e par', ' park', 'park ', 'ark a', 'rk af', 'k aft', ' afte', 'after', 'fter ', 'ter b', 'er bu', 'r buy', ' buyi', 'buyin', 'uying', 'ying ', 'ing i', 'ng ic', 'g ice', ' ice ', 'ice c', 'ce cr', 'e cre', ' crea', 'cream']\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rDn600cSucGy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "f25f9dd5-7cea-4c07-fb86-4127d15ada9e"
      },
      "source": [
        "# show the model output using predict function\n",
        "# Enter your code here:\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "  \n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(X, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text_input) - new_window_size - 1)\n",
        "    generated_text = text_input[start_index: start_index + new_window_size]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ temperature:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # We generate 400 characters\n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, new_window_size, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"gru_input:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 5, 35).\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9859 - acc: 0.4298\n",
            "--- Generating with seed: \", esp\"\n",
            "------ temperature: 0.2\n",
            ", espWARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"gru_input:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 5, 35).\n",
            "er, and that have you stated in that have you shall down which had starry, but the diston, which what sent comparringg the down with the leave courtth. i fellow, and that heavely. it was all porrougghed that she was hand which stair should beforr wand that heave in that her was the man stair note was all to there was she was stepper, and the seemen, what she was all the door which stair should dow\n",
            "------ temperature: 0.5\n",
            "d down keepence, that sen that wher father camp the was wand seemed. the sompleine from have light heard off untill dest from and that paper day inter windo have leavely. which leaven, i have me to there, down from in his should inter and house, and office ask ifter may bange been centread. i have next him, and very has steppory. it man wing inter off cours. what with and of singul window, may not sher\n",
            "------ temperature: 1.0\n",
            " shert know mark, upter:?'chat?a'sly; it is.wh hig what charbandursxhappines courds? but the would dodry, fact. you mj. provabley that she mun. my scall-n:gjeytu.nees who min ofyers, smilit. do to parite. man'ss concied nocke:, it sinclied, the me.sherlees! the dadiert let.'wnow, theng-king hambbuck, fut my het profie, we leave clotay.''thislionk. the mectwh, concrodowspryeec fall-dxabst, vellay, rone,\n",
            "------ temperature: 1.2\n",
            "rone, she my awayspleque, of that hoadsy: vasablwy. therexjeargz was as edver.b'collvbel. i canted-veily.,'nure!qyuzer,d. i a vigieszht?'ke king jusps; all.'i's, manns? thehe?''thr. then upent, goze' parrs.gurled and lord you.gare?ife''s;! ther'pyt.him? 'hurrs, mssew-geats, when have persesverp, loke prosast quickt's,book,dhe dred.pectatzuchath palk remels kincod!would, i shatem's; rondeths! that ixil,\n",
            "epoch 2\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9773 - acc: 0.4474\n",
            "--- Generating with seed: \"ry sa\"\n",
            "------ temperature: 0.2\n",
            "ry same very was all purse, which stree. it was all the door whole windon who may seemed. i have the call dight had beard inter with the man who was sheet littly seemed. i should the man which officel stair no, and the littly seemed in the stated in that man where with the seen in that stair note which stair note was all the seen who is that heard inter was the door whose which hand story, the man who \n",
            "------ temperature: 0.5\n",
            " who is, which carridg, for greet in the dight of his should mr. he was the seemen's whole, were window inter was comporried. i have comples. it was were off the with of his have in that her sature. the that would pross known down carrods. i shally that way the door, flack, has conlice. he was ard and that been tide which ampress. where smokent in sighturned great son, you have the carryd. come new man\n",
            "------ temperature: 1.0\n",
            "w man. i have inter-crakn-tthe man his caped sen mady atwhere weddeveable, with i have juallzqaudsever, that dearl liary quusigh, his koung.where bolice. husthe: if i his inds inter yeviles! with yothi. we lisel.'jop kindly polestjukcuenc. ofthreea:vincearls!, runikne, but hid when him. i never im some knock.hours!mine give quiealnd set by his expocopppeaclu,cyeddrefor would readv'bers!leep,a broaked, \n",
            "------ temperature: 1.2\n",
            "ked, houriggls. off her proviage close,thery:cokfourded verss. homme. profogner, turnee, by kiven kinclya;go, make you hand incen ject,the's, leade. icqua yonwardty. just find that nige.jurgeg, jede,'?'y!'''k?d. vonee, nothingly--agquirne?thark geever rase crudps wilass pallev jest murd'! it.johker.;o', doorevenk. it sever.'jumrm'sm. ' brody!'''quser fellfotcheecasz,dirn, were handdcars brighat, socqu,\n",
            "epoch 3\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9611 - acc: 0.4474\n",
            "--- Generating with seed: \" satr\"\n",
            "------ temperature: 0.2\n",
            " satreed with the man where with the littly seeme! i have you there with the bed that seemen who may stair shair shair lite was all the littly self man she was all post the court off the man which office, and the distray. i shall dight seemed in the court, which ask into seen with the court, which stair note with the man who way the littly seeme. it was all the call off the door preass the doubled, i h\n",
            "------ temperature: 0.5\n",
            ", i have news inter mance tower, at the man. i will fample sempthery offorr ist and man who was almand, was the looking hand sent have comper deart, have very strieed of see throumse with in seme for and man whole was abluied, which make colour dees than was sevile. i had bell-y; but the man, he were aster dign the duried that when have yes, the for and in from the case were which laid in though me thi\n",
            "------ temperature: 1.0\n",
            "e thienste. icould,'s and whaturwnong. the his night; i have fine chan. only.what sherle?noth sever?divory fell, man like all to the besing mornike. i from briviel empreats: flory, show. is anntard. you man heavy odjer. nocte, by two digh, i see efroub gice. and had the yespe colonge had could, wasto;s:''wn! and for this morning in seens, tocomp-ofthe marrid, i wouldrceal have counst being couph for pr\n",
            "------ temperature: 1.2\n",
            "or prisy lodgep adcrubgal sagad rosmem is upfatem. thisaq aking?av?it.' he's: theeeed, aghiund kistesteppirtablle, very polit, quitrusel, of jehs quautberak astre velloymon, but apppcipar.what hat.'k-hand, brien, andy: gave in thing workhalld ady siig.th and invider, juttryuadzed felfok! she discamm.this ualond smulf-y-of--quanb. inskly covined mornign lawapzr:,w if it lacke, on that driwnce drapp ofr \n",
            "epoch 4\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9384 - acc: 0.4474\n",
            "--- Generating with seed: \" satr\"\n",
            "------ temperature: 0.2\n",
            " satree with the courtth me that was all porried. i should not seemed. i have you man who was all press. the lough, the seemed in the man who way this have courtth, i have in that she was the like which stair note which happer, and the carridge to the looked, the case which off the dear gure chairn good stair shate which stair shair note which stair sheet lange with the think have courst and the doung \n",
            "------ temperature: 0.5\n",
            "oung shown. you may sent seemed, remaid the doubter very sat the comparry dear night, he have in that bee, man window and the off the readly dour windown, the came think looking of man, what well, drawh, but she that inaty, but the lange littly work inter wingoh, the me to bele and who way to charrd, of the had dister priest still after office, if your chall porried in upon which marry, fact him?i do n\n",
            "------ temperature: 1.0\n",
            " do nom loudo lat agapip; not uppos?see, raturlabhourdvil;and, pork jomme: in servaidy visit vosurd. i threa. cotter escen? i heaid lakes. there, which looke; exple?be commaking hadd upon prisete court! in told his coppearing gaist!'and fachht me, for geast,-hair, yousagh,, and seee door it severge compair nall, withes seemedstep, whiling trreaid, the i fairl window?'t.le! 'what with same; mr; juger, b\n",
            "------ temperature: 1.2\n",
            "er, but mistly thicke, viole.wehadgvemay jece,-hower.'''h:'!''pprariyg!sthatne.y.lesthree., he did is reave we doying, of felenw pallimops? the loddifty day, what this francy.jakif, theeal gap: land;a havey!''f, lefenguarranth seed--nobls, have chproandgrow---barncink,there, viough for the might two loctrlyianct.y'men?what seer agry, wear'duph, the cliare?'s young.too? have therou.''llo;g.he hasfe?xani\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2J32hlGhucG1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a2616946-8ff6-4807-a666-5ef941a67473"
      },
      "source": [
        "model.fit(X, y, batch_size=128, epochs=1)\n",
        "\n",
        "text_ls = [\"dogs are grea\", \"please ente\", \"what a sigh\", \"edge of the worl\", \"would you please hurr\"]\n",
        "temperature = 0.2\n",
        "print('------ temperature:', temperature)\n",
        "print(\"Prediction: \")\n",
        "for i in text_ls:\n",
        "  sys.stdout.write(i)\n",
        "\n",
        "  # We generate 400 characters\n",
        "  # for i in range(400):\n",
        "  sampled = np.zeros((1, len(i), len(chars)))\n",
        "  for t, char in enumerate(i):\n",
        "      sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "  preds = model.predict(sampled, verbose=0)[0]\n",
        "  next_index = sample(preds, temperature)\n",
        "  next_char = chars[next_index]\n",
        "\n",
        "  sys.stdout.write(next_char)\n",
        "  sys.stdout.flush()\n",
        "  print()\n",
        "\n",
        "\n",
        "text_input = input(\"Enter sentence to predict next character: \\n\")\n",
        "print(\"Predicting user input... \\n\")\n",
        "sys.stdout.write(text_input)\n",
        "\n",
        "# We generate 400 characters\n",
        "# for i in range(400):\n",
        "sampled = np.zeros((1, len(text_input), len(chars)))\n",
        "for t, char in enumerate(text_input):\n",
        "    sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "preds = model.predict(sampled, verbose=0)[0]\n",
        "next_index = sample(preds, temperature)\n",
        "next_char = chars[next_index]\n",
        "\n",
        "text_input += next_char\n",
        "text_input = text_input[1:]\n",
        "\n",
        "\n",
        "sys.stdout.write(next_char)\n",
        "sys.stdout.flush()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9773 - acc: 0.4474\n",
            "------ temperature: 0.2\n",
            "Prediction: \n",
            "dogs are great\n",
            "please enter\n",
            "what a sight\n",
            "edge of the world\n",
            "would you please hurri\n",
            "Enter sentence to predict next character: \n",
            "i am so happ\n",
            "Predicting user input... \n",
            "\n",
            "i am so happy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vsrSzmfD9S0e"
      },
      "source": [
        "#### Evaluation [chgen_model_2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D9F4_RJD9S0g",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "\n",
        "\n",
        "#model.load_weights('chgen_model_best.h5')\n",
        "model = models.load_model(model_path+'chgen_model_10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1BragFNm9S0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f751babd-9ba4-446e-d063-4b8b49974d15"
      },
      "source": [
        "# takes the user input\n",
        "\n",
        "#text_input = np.array([input()])\n",
        "text_input = clean_text(input().lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oh's third victim was hawker stall owner Ng Phek Huay, whom he stole from on Sept 9, 2019.  While Madam Ng, 71, was waiting for her turn to see the doctor at Queenstown Polyclinic, he stole money from her handbag.  He then offered her zopiclone and convinced her that she had to take it before her medical check-up.  Thinking that Oh was one of the polyclinic staff, Madam Ng took the drug and became drowsy.  He then took from her a gold-coloured bracelet which she was wearing and took her out of the polyclinic.  Oh then got a taxi to take Madam Ng to NUH, as she was losing consciousness.  On Friday, District Judge Gwee backdated Oh's sentence to Sept 12 last year, when he was first remanded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w1dJaMX19S0o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fff7a1fd-5d3f-457d-8f5d-4c0e34f18ae0"
      },
      "source": [
        "# one-hot encode the user input\n",
        "# Enter your code here:\n",
        "new_window_size = 10\n",
        "\n",
        "X, y = encode_io_pairs(text_input, new_window_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of Sequences:  679\n",
            "[\"oh's third\", \"h's third \", \"'s third v\", 's third vi', ' third vic', 'third vict', 'hird victi', 'ird victim', 'rd victim ', 'd victim w', ' victim wa', 'victim was', 'ictim was ', 'ctim was h', 'tim was ha', 'im was haw', 'm was hawk', ' was hawke', 'was hawker', 'as hawker ', 's hawker s', ' hawker st', 'hawker sta', 'awker stal', 'wker stall', 'ker stall ', 'er stall o', 'r stall ow', ' stall own', 'stall owne', 'tall owner', 'all owner ', 'll owner n', 'l owner ng', ' owner ng ', 'owner ng p', 'wner ng ph', 'ner ng phe', 'er ng phek', 'r ng phek ', ' ng phek h', 'ng phek hu', 'g phek hua', ' phek huay', 'phek huay,', 'hek huay, ', 'ek huay, w', 'k huay, wh', ' huay, who', 'huay, whom', 'uay, whom ', 'ay, whom h', 'y, whom he', ', whom he ', ' whom he s', 'whom he st', 'hom he sto', 'om he stol', 'm he stole', ' he stole ', 'he stole f', 'e stole fr', ' stole fro', 'stole from', 'tole from ', 'ole from o', 'le from on', 'e from on ', ' from on s', 'from on se', 'rom on sep', 'om on sept', 'm on sept ', ' on sept ,', 'on sept , ', 'n sept , .', ' sept , . ', 'sept , .  ', 'ept , .  w', 'pt , .  wh', 't , .  whi', ' , .  whil', ', .  while', ' .  while ', '.  while m', '  while ma', ' while mad', 'while mada', 'hile madam', 'ile madam ', 'le madam n', 'e madam ng', ' madam ng,', 'madam ng, ', 'adam ng, ,', 'dam ng, , ', 'am ng, , w', 'm ng, , wa', ' ng, , was', 'ng, , was ', 'g, , was w', ', , was wa', ' , was wai', ', was wait', ' was waiti', 'was waitin', 'as waiting', 's waiting ', ' waiting f', 'waiting fo', 'aiting for', 'iting for ', 'ting for h', 'ing for he', 'ng for her', 'g for her ', ' for her t', 'for her tu', 'or her tur', 'r her turn', ' her turn ', 'her turn t', 'er turn to', 'r turn to ', ' turn to s', 'turn to se', 'urn to see', 'rn to see ', 'n to see t', ' to see th', 'to see the', 'o see the ', ' see the d', 'see the do', 'ee the doc', 'e the doct', ' the docto', 'the doctor', 'he doctor ', 'e doctor a', ' doctor at', 'doctor at ', 'octor at q', 'ctor at qu', 'tor at que', 'or at quee', 'r at queen', ' at queens', 'at queenst', 't queensto', ' queenstow', 'queenstown', 'ueenstown ', 'eenstown p', 'enstown po', 'nstown pol', 'stown poly', 'town polyc', 'own polycl', 'wn polycli', 'n polyclin', ' polyclini', 'polyclinic', 'olyclinic,', 'lyclinic, ', 'yclinic, h', 'clinic, he', 'linic, he ', 'inic, he s', 'nic, he st', 'ic, he sto', 'c, he stol', ', he stole', ' he stole ', 'he stole m', 'e stole mo', ' stole mon', 'stole mone', 'tole money', 'ole money ', 'le money f', 'e money fr', ' money fro', 'money from', 'oney from ', 'ney from h', 'ey from he', 'y from her', ' from her ', 'from her h', 'rom her ha', 'om her han', 'm her hand', ' her handb', 'her handba', 'er handbag', 'r handbag.', ' handbag. ', 'handbag.  ', 'andbag.  h', 'ndbag.  he', 'dbag.  he ', 'bag.  he t', 'ag.  he th', 'g.  he the', '.  he then', '  he then ', ' he then o', 'he then of', 'e then off', ' then offe', 'then offer', 'hen offere', 'en offered', 'n offered ', ' offered h', 'offered he', 'ffered her', 'fered her ', 'ered her z', 'red her zo', 'ed her zop', 'd her zopi', ' her zopic', 'her zopicl', 'er zopiclo', 'r zopiclon', ' zopiclone', 'zopiclone ', 'opiclone a', 'piclone an', 'iclone and', 'clone and ', 'lone and c', 'one and co', 'ne and con', 'e and conv', ' and convi', 'and convin', 'nd convinc', 'd convince', ' convinced', 'convinced ', 'onvinced h', 'nvinced he', 'vinced her', 'inced her ', 'nced her t', 'ced her th', 'ed her tha', 'd her that', ' her that ', 'her that s', 'er that sh', 'r that she', ' that she ', 'that she h', 'hat she ha', 'at she had', 't she had ', ' she had t', 'she had to', 'he had to ', 'e had to t', ' had to ta', 'had to tak', 'ad to take', 'd to take ', ' to take i', 'to take it', 'o take it ', ' take it b', 'take it be', 'ake it bef', 'ke it befo', 'e it befor', ' it before', 'it before ', 't before h', ' before he', 'before her', 'efore her ', 'fore her m', 'ore her me', 're her med', 'e her medi', ' her medic', 'her medica', 'er medical', 'r medical ', ' medical c', 'medical ch', 'edical che', 'dical chec', 'ical check', 'cal check-', 'al check-u', 'l check-up', ' check-up.', 'check-up. ', 'heck-up.  ', 'eck-up.  t', 'ck-up.  th', 'k-up.  thi', '-up.  thin', 'up.  think', 'p.  thinki', '.  thinkin', '  thinking', ' thinking ', 'thinking t', 'hinking th', 'inking tha', 'nking that', 'king that ', 'ing that o', 'ng that oh', 'g that oh ', ' that oh w', 'that oh wa', 'hat oh was', 'at oh was ', 't oh was o', ' oh was on', 'oh was one', 'h was one ', ' was one o', 'was one of', 'as one of ', 's one of t', ' one of th', 'one of the', 'ne of the ', 'e of the p', ' of the po', 'of the pol', 'f the poly', ' the polyc', 'the polycl', 'he polycli', 'e polyclin', ' polyclini', 'polyclinic', 'olyclinic ', 'lyclinic s', 'yclinic st', 'clinic sta', 'linic staf', 'inic staff', 'nic staff,', 'ic staff, ', 'c staff, m', ' staff, ma', 'staff, mad', 'taff, mada', 'aff, madam', 'ff, madam ', 'f, madam n', ', madam ng', ' madam ng ', 'madam ng t', 'adam ng to', 'dam ng too', 'am ng took', 'm ng took ', ' ng took t', 'ng took th', 'g took the', ' took the ', 'took the d', 'ook the dr', 'ok the dru', 'k the drug', ' the drug ', 'the drug a', 'he drug an', 'e drug and', ' drug and ', 'drug and b', 'rug and be', 'ug and bec', 'g and beca', ' and becam', 'and became', 'nd became ', 'd became d', ' became dr', 'became dro', 'ecame drow', 'came drows', 'ame drowsy', 'me drowsy.', 'e drowsy. ', ' drowsy.  ', 'drowsy.  h', 'rowsy.  he', 'owsy.  he ', 'wsy.  he t', 'sy.  he th', 'y.  he the', '.  he then', '  he then ', ' he then t', 'he then to', 'e then too', ' then took', 'then took ', 'hen took f', 'en took fr', 'n took fro', ' took from', 'took from ', 'ook from h', 'ok from he', 'k from her', ' from her ', 'from her a', 'rom her a ', 'om her a g', 'm her a go', ' her a gol', 'her a gold', 'er a gold-', 'r a gold-c', ' a gold-co', 'a gold-col', ' gold-colo', 'gold-colou', 'old-colour', 'ld-coloure', 'd-coloured', '-coloured ', 'coloured b', 'oloured br', 'loured bra', 'oured brac', 'ured brace', 'red bracel', 'ed bracele', 'd bracelet', ' bracelet ', 'bracelet w', 'racelet wh', 'acelet whi', 'celet whic', 'elet which', 'let which ', 'et which s', 't which sh', ' which she', 'which she ', 'hich she w', 'ich she wa', 'ch she was', 'h she was ', ' she was w', 'she was we', 'he was wea', 'e was wear', ' was weari', 'was wearin', 'as wearing', 's wearing ', ' wearing a', 'wearing an', 'earing and', 'aring and ', 'ring and t', 'ing and to', 'ng and too', 'g and took', ' and took ', 'and took h', 'nd took he', 'd took her', ' took her ', 'took her o', 'ook her ou', 'ok her out', 'k her out ', ' her out o', 'her out of', 'er out of ', 'r out of t', ' out of th', 'out of the', 'ut of the ', 't of the p', ' of the po', 'of the pol', 'f the poly', ' the polyc', 'the polycl', 'he polycli', 'e polyclin', ' polyclini', 'polyclinic', 'olyclinic.', 'lyclinic. ', 'yclinic.  ', 'clinic.  o', 'linic.  oh', 'inic.  oh ', 'nic.  oh t', 'ic.  oh th', 'c.  oh the', '.  oh then', '  oh then ', ' oh then g', 'oh then go', 'h then got', ' then got ', 'then got a', 'hen got a ', 'en got a t', 'n got a ta', ' got a tax', 'got a taxi', 'ot a taxi ', 't a taxi t', ' a taxi to', 'a taxi to ', ' taxi to t', 'taxi to ta', 'axi to tak', 'xi to take', 'i to take ', ' to take m', 'to take ma', 'o take mad', ' take mada', 'take madam', 'ake madam ', 'ke madam n', 'e madam ng', ' madam ng ', 'madam ng t', 'adam ng to', 'dam ng to ', 'am ng to n', 'm ng to nu', ' ng to nuh', 'ng to nuh,', 'g to nuh, ', ' to nuh, a', 'to nuh, as', 'o nuh, as ', ' nuh, as s', 'nuh, as sh', 'uh, as she', 'h, as she ', ', as she w', ' as she wa', 'as she was', 's she was ', ' she was l', 'she was lo', 'he was los', 'e was losi', ' was losin', 'was losing', 'as losing ', 's losing c', ' losing co', 'losing con', 'osing cons', 'sing consc', 'ing consci', 'ng conscio', 'g consciou', ' conscious', 'consciousn', 'onsciousne', 'nsciousnes', 'sciousness', 'ciousness.', 'iousness. ', 'ousness.  ', 'usness.  o', 'sness.  on', 'ness.  on ', 'ess.  on f', 'ss.  on fr', 's.  on fri', '.  on frid', '  on frida', ' on friday', 'on friday,', 'n friday, ', ' friday, d', 'friday, di', 'riday, dis', 'iday, dist', 'day, distr', 'ay, distri', 'y, distric', ', district', ' district ', 'district j', 'istrict ju', 'strict jud', 'trict judg', 'rict judge', 'ict judge ', 'ct judge g', 't judge gw', ' judge gwe', 'judge gwee', 'udge gwee ', 'dge gwee b', 'ge gwee ba', 'e gwee bac', ' gwee back', 'gwee backd', 'wee backda', 'ee backdat', 'e backdate', ' backdated', 'backdated ', 'ackdated o', 'ckdated oh', \"kdated oh'\", \"dated oh's\", \"ated oh's \", \"ted oh's s\", \"ed oh's se\", \"d oh's sen\", \" oh's sent\", \"oh's sente\", \"h's senten\", \"'s sentenc\", 's sentence', ' sentence ', 'sentence t', 'entence to', 'ntence to ', 'tence to s', 'ence to se', 'nce to sep', 'ce to sept', 'e to sept ', ' to sept  ', 'to sept  l', 'o sept  la', ' sept  las', 'sept  last', 'ept  last ', 'pt  last y', 't  last ye', '  last yea', ' last year', 'last year,', 'ast year, ', 'st year, w', 't year, wh', ' year, whe', 'year, when', 'ear, when ', 'ar, when h', 'r, when he', ', when he ', ' when he w', 'when he wa', 'hen he was', 'en he was ', 'n he was f', ' he was fi', 'he was fir', 'e was firs', ' was first', 'was first ', 'as first r', 's first re', ' first rem', 'first rema', 'irst reman', 'rst remand', 'st remande', 't remanded']\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JZSLF42v9S0r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "e1e6afa0-78d5-460f-d244-76604d984e32"
      },
      "source": [
        "# show the model output using predict function\n",
        "# Enter your code here:\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "  \n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(X, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text_input) - new_window_size - 1)\n",
        "    generated_text = text_input[start_index: start_index + new_window_size]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ temperature:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # We generate 400 characters\n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, new_window_size, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"gru_input_1:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 10, 35).\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.0153 - acc: 0.4404\n",
            "--- Generating with seed: \"am ng took\"\n",
            "------ temperature: 0.2\n",
            "am ng tookWARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"gru_input_1:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 10, 35).\n",
            " a start and the street of the street of the secret the companion of the strange and have been street of the state and the dear from the coroner to me that he was a shall of the secret the street and the dear which i have been street. i have not be a little the lady with his face and the from the companion which he see that i am some of the strange of the coroner was a sure that was the concent a \n",
            "------ temperature: 0.5\n",
            "concent a put upon the componition as the face and the gland. left he had been at the back so the fire at the did at the pater of the police we shall double and was done that he has had been as he was a face street, for the points of the hat she was very more man. he said that it was a fair for his on the could not seem to be the companion and sat such a chriet. i have man which had suddenly not me that he \n",
            "------ temperature: 1.0\n",
            "e that he found it, and face a whose usel from histleed suwhis now father as neveltyres trust and men and packed in at sayrown was eirepention, and the so. we,phise vulally; four compenty londsbake and rematured iffor a quarter off in found, wearse upun upon beghat the fing, with us. the fire to his, so that hers laid, i had sairmafiou and feates, bat! seese me to trubth. gave my less stoized the same lockn\n",
            "------ temperature: 1.2\n",
            "same locknct.whywalknd up a glestrost caman, then as thetertot wastower as wonter pazedbud whearsweaid in crible papsed boors flent, visat bike as abeling, as hot a little fram off themood up, and i westergoon, that he have dareled in a cheld of youts contentive mait?''you whatas steed by a sincelung when yourescree, briak? is nof speem. ita huspprentem' stalk goxe toa coff, miss,said it dumbit mad-milednot\n",
            "epoch 2\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9513 - acc: 0.4580\n",
            "--- Generating with seed: \"udge gwee \"\n",
            "------ temperature: 0.2\n",
            "udge gwee and the first that he had been street of his face and the fact of the strange to the first the companion was a start and the concent of the street and the morning the street and the thing i have some close that he was a start to the strange a state and the matter was still to the hands of the fire the room which we have been street. he was a start in the street of her street and the country of the\n",
            "------ temperature: 0.5\n",
            "try of the chack from the face with the matter be some has been still some street. he was a man who said her to let me reason, and the fact and the other was a start to the attenting which he came a street a friend of the best remained to the copper the same was father that he patter and confriend the desting from her the advertime to be so the morning the first to the struct at my friend the which he had s\n",
            "------ temperature: 1.0\n",
            "h he had sobve lay she heard dispung succoung eppeaned wild's pape.seen their lees chant word. the preiened, all onling threquiches wind of he dedicate build.here word to little and implentrem sfirm sech savence no, 'wave that he, righted in six a veathing her awulpref and at his garde when pouning state, fathenc-me.penhar, so i shill a case, let knote of bo horefthe taw near to her. dirtime friend occproso\n",
            "------ temperature: 1.2\n",
            "d occprosonth, who is sevicaling recage of usuable fousts. roliif from yest haveloran. and from atmiss story' was in coming lady glance 'breathed uncentled lafe.'she day  mole go;s natured, thy looken?th ! shen merrally! i have just hen sim folmown was dank whatpemp the opinit calkingle's ofin way, who 'walked in paper bedoh, or pegcrs,it in fail prapbravesque,puplic ascopmeddess objea hurter hum good senpe\n",
            "epoch 3\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8610 - acc: 0.4728\n",
            "--- Generating with seed: \"me drowsy.\"\n",
            "------ temperature: 0.2\n",
            "me drowsy. i should be seemed to the charge and the dear the charge the lady face and the man was a state of the next seemed to the charce for the chair in the room of the door was a paper which he was a start of her before the facts in the door be a little the paper state which he had been start and the chance of the strange and her the first that he stone close and the stated me that he had been street of\n",
            "------ temperature: 0.5\n",
            " street of his father before in should be the dest the coldrage that he was not in strange in strick had come for me the best the head was a way. i am to the compance in the strugg to have been and the inness for a contray when he case be a large that the corone was help the dayce and the convince as the child holmes and looking, and stated to see the trace down with his should be the face, when he have bee\n",
            "------ temperature: 1.0\n",
            "e have beer which was holmes conter screem making catter. prictic. the tawing bet evance more thece-coroned take havinug at the choldge than what dy precers as exomed uponeim parred trapositit dour, it, and her light of my matters house i narust. as we do sure that it was from that i had fect find way of course to do it throw.' she case in the shoundbriding, whit, stair and herlanced cleath. brow that the r\n",
            "------ temperature: 1.2\n",
            "that the row how some fable?very sixfor adveven.there's nwy yes nister breckil oft her peomined on, frem than he consureming epred upon feg hadrether who appainly. i have no dever.just he wher o'clec-pliaple,-xay much peppoin for himselver:ly. tretaun.it mertanffarse imrom, then less unilp in when he had. did i doden compans in helves sade no inval as reashes. it he distlerenc, by asheri. rich stayin thrown\n",
            "epoch 4\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7683 - acc: 0.5022\n",
            "--- Generating with seed: \".  oh then\"\n",
            "------ temperature: 0.2\n",
            ".  oh then he was a start and the matter who had been a charce with her stated be a case of the strange of the strange that he was a few man, and the facts which i have not the police and the strange and the state when he was a decest the chair and the concent that he had been the paper state which he had been and the fact of the fact of the street of the present and the fact of the strange that he was a st\n",
            "------ temperature: 0.5\n",
            "e was a street of her had fact that he was a decess to the crime that she heard that they were to see the matter and have before he saw of the ghance that she had conting had a long from her leg to the first the lose from her the morting of the charm when he was not over the chair in the money could be a found the strong had been such a struggless the policed to see the fall in she house of the strange and \n",
            "------ temperature: 1.0\n",
            "range and lady came reasonnder years and from a hed cause of they innoccupled and packs if the doline. mr. had no one of look eham enclips and?i challed as why belingly have, said he; said he. the man, sil, changed find.fell his chy, and i marice address, the miss heaphing los jude for me. he was elst to cas just nottes: the onliev, the great sund dark who have anchound mode.yes, mr. then shewlock her the v\n",
            "------ temperature: 1.2\n",
            " her the vair.'therefrie nating corangroven stgit then. then,'wren you clot.'then reccanger. shiling charint 'by naturgly, of icnuen enougg fry chamcex for exation. he hadfred done clot, it wewall. some abproasest knew him. yownetthe straigh and face, with radabloked to gastly-room, bet dr. no my it? if you would wavefhe myeccnew twof,chay lent at, stole!i spoke twouk of lees her a countcrap-hord, chentra't\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Q41dnxD5XCB"
      },
      "source": [
        "## Step 3 – Use the Best Model to make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_ZsPM0jGLew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "model = models.load_model(model_path+'chgen_model_2.h5')\n",
        "model.save(model_path+'chgen_model_best.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sn9HJbJB5XCC",
        "colab": {}
      },
      "source": [
        "\n",
        "model = models.load_model(model_path+ 'chgen_model_best.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c1LlaagD5XCE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9490fffa-489c-483b-f5b8-32fa63a392b3"
      },
      "source": [
        "# takes the user input\n",
        "\n",
        "#text_input = np.array([input()])\n",
        "text_input = clean_text(input().lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oh's third victim was hawker stall owner Ng Phek Huay, whom he stole from on Sept 9, 2019.  While Madam Ng, 71, was waiting for her turn to see the doctor at Queenstown Polyclinic, he stole money from her handbag.  He then offered her zopiclone and convinced her that she had to take it before her medical check-up.  Thinking that Oh was one of the polyclinic staff, Madam Ng took the drug and became drowsy.  He then took from her a gold-coloured bracelet which she was wearing and took her out of the polyclinic.  Oh then got a taxi to take Madam Ng to NUH, as she was losing consciousness.  On Friday, District Judge Gwee backdated Oh's sentence to Sept 12 last year, when he was first remanded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMA3kSyI5XCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "2c83d24b-6556-47c5-a2cf-8c86a4daf763"
      },
      "source": [
        "# one-hot encode the user input\n",
        "# Enter your code here:\n",
        "new_window_size = 10\n",
        "\n",
        "X, y = encode_io_pairs(text_input, new_window_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of Sequences:  679\n",
            "[\"oh's third\", \"h's third \", \"'s third v\", 's third vi', ' third vic', 'third vict', 'hird victi', 'ird victim', 'rd victim ', 'd victim w', ' victim wa', 'victim was', 'ictim was ', 'ctim was h', 'tim was ha', 'im was haw', 'm was hawk', ' was hawke', 'was hawker', 'as hawker ', 's hawker s', ' hawker st', 'hawker sta', 'awker stal', 'wker stall', 'ker stall ', 'er stall o', 'r stall ow', ' stall own', 'stall owne', 'tall owner', 'all owner ', 'll owner n', 'l owner ng', ' owner ng ', 'owner ng p', 'wner ng ph', 'ner ng phe', 'er ng phek', 'r ng phek ', ' ng phek h', 'ng phek hu', 'g phek hua', ' phek huay', 'phek huay,', 'hek huay, ', 'ek huay, w', 'k huay, wh', ' huay, who', 'huay, whom', 'uay, whom ', 'ay, whom h', 'y, whom he', ', whom he ', ' whom he s', 'whom he st', 'hom he sto', 'om he stol', 'm he stole', ' he stole ', 'he stole f', 'e stole fr', ' stole fro', 'stole from', 'tole from ', 'ole from o', 'le from on', 'e from on ', ' from on s', 'from on se', 'rom on sep', 'om on sept', 'm on sept ', ' on sept ,', 'on sept , ', 'n sept , .', ' sept , . ', 'sept , .  ', 'ept , .  w', 'pt , .  wh', 't , .  whi', ' , .  whil', ', .  while', ' .  while ', '.  while m', '  while ma', ' while mad', 'while mada', 'hile madam', 'ile madam ', 'le madam n', 'e madam ng', ' madam ng,', 'madam ng, ', 'adam ng, ,', 'dam ng, , ', 'am ng, , w', 'm ng, , wa', ' ng, , was', 'ng, , was ', 'g, , was w', ', , was wa', ' , was wai', ', was wait', ' was waiti', 'was waitin', 'as waiting', 's waiting ', ' waiting f', 'waiting fo', 'aiting for', 'iting for ', 'ting for h', 'ing for he', 'ng for her', 'g for her ', ' for her t', 'for her tu', 'or her tur', 'r her turn', ' her turn ', 'her turn t', 'er turn to', 'r turn to ', ' turn to s', 'turn to se', 'urn to see', 'rn to see ', 'n to see t', ' to see th', 'to see the', 'o see the ', ' see the d', 'see the do', 'ee the doc', 'e the doct', ' the docto', 'the doctor', 'he doctor ', 'e doctor a', ' doctor at', 'doctor at ', 'octor at q', 'ctor at qu', 'tor at que', 'or at quee', 'r at queen', ' at queens', 'at queenst', 't queensto', ' queenstow', 'queenstown', 'ueenstown ', 'eenstown p', 'enstown po', 'nstown pol', 'stown poly', 'town polyc', 'own polycl', 'wn polycli', 'n polyclin', ' polyclini', 'polyclinic', 'olyclinic,', 'lyclinic, ', 'yclinic, h', 'clinic, he', 'linic, he ', 'inic, he s', 'nic, he st', 'ic, he sto', 'c, he stol', ', he stole', ' he stole ', 'he stole m', 'e stole mo', ' stole mon', 'stole mone', 'tole money', 'ole money ', 'le money f', 'e money fr', ' money fro', 'money from', 'oney from ', 'ney from h', 'ey from he', 'y from her', ' from her ', 'from her h', 'rom her ha', 'om her han', 'm her hand', ' her handb', 'her handba', 'er handbag', 'r handbag.', ' handbag. ', 'handbag.  ', 'andbag.  h', 'ndbag.  he', 'dbag.  he ', 'bag.  he t', 'ag.  he th', 'g.  he the', '.  he then', '  he then ', ' he then o', 'he then of', 'e then off', ' then offe', 'then offer', 'hen offere', 'en offered', 'n offered ', ' offered h', 'offered he', 'ffered her', 'fered her ', 'ered her z', 'red her zo', 'ed her zop', 'd her zopi', ' her zopic', 'her zopicl', 'er zopiclo', 'r zopiclon', ' zopiclone', 'zopiclone ', 'opiclone a', 'piclone an', 'iclone and', 'clone and ', 'lone and c', 'one and co', 'ne and con', 'e and conv', ' and convi', 'and convin', 'nd convinc', 'd convince', ' convinced', 'convinced ', 'onvinced h', 'nvinced he', 'vinced her', 'inced her ', 'nced her t', 'ced her th', 'ed her tha', 'd her that', ' her that ', 'her that s', 'er that sh', 'r that she', ' that she ', 'that she h', 'hat she ha', 'at she had', 't she had ', ' she had t', 'she had to', 'he had to ', 'e had to t', ' had to ta', 'had to tak', 'ad to take', 'd to take ', ' to take i', 'to take it', 'o take it ', ' take it b', 'take it be', 'ake it bef', 'ke it befo', 'e it befor', ' it before', 'it before ', 't before h', ' before he', 'before her', 'efore her ', 'fore her m', 'ore her me', 're her med', 'e her medi', ' her medic', 'her medica', 'er medical', 'r medical ', ' medical c', 'medical ch', 'edical che', 'dical chec', 'ical check', 'cal check-', 'al check-u', 'l check-up', ' check-up.', 'check-up. ', 'heck-up.  ', 'eck-up.  t', 'ck-up.  th', 'k-up.  thi', '-up.  thin', 'up.  think', 'p.  thinki', '.  thinkin', '  thinking', ' thinking ', 'thinking t', 'hinking th', 'inking tha', 'nking that', 'king that ', 'ing that o', 'ng that oh', 'g that oh ', ' that oh w', 'that oh wa', 'hat oh was', 'at oh was ', 't oh was o', ' oh was on', 'oh was one', 'h was one ', ' was one o', 'was one of', 'as one of ', 's one of t', ' one of th', 'one of the', 'ne of the ', 'e of the p', ' of the po', 'of the pol', 'f the poly', ' the polyc', 'the polycl', 'he polycli', 'e polyclin', ' polyclini', 'polyclinic', 'olyclinic ', 'lyclinic s', 'yclinic st', 'clinic sta', 'linic staf', 'inic staff', 'nic staff,', 'ic staff, ', 'c staff, m', ' staff, ma', 'staff, mad', 'taff, mada', 'aff, madam', 'ff, madam ', 'f, madam n', ', madam ng', ' madam ng ', 'madam ng t', 'adam ng to', 'dam ng too', 'am ng took', 'm ng took ', ' ng took t', 'ng took th', 'g took the', ' took the ', 'took the d', 'ook the dr', 'ok the dru', 'k the drug', ' the drug ', 'the drug a', 'he drug an', 'e drug and', ' drug and ', 'drug and b', 'rug and be', 'ug and bec', 'g and beca', ' and becam', 'and became', 'nd became ', 'd became d', ' became dr', 'became dro', 'ecame drow', 'came drows', 'ame drowsy', 'me drowsy.', 'e drowsy. ', ' drowsy.  ', 'drowsy.  h', 'rowsy.  he', 'owsy.  he ', 'wsy.  he t', 'sy.  he th', 'y.  he the', '.  he then', '  he then ', ' he then t', 'he then to', 'e then too', ' then took', 'then took ', 'hen took f', 'en took fr', 'n took fro', ' took from', 'took from ', 'ook from h', 'ok from he', 'k from her', ' from her ', 'from her a', 'rom her a ', 'om her a g', 'm her a go', ' her a gol', 'her a gold', 'er a gold-', 'r a gold-c', ' a gold-co', 'a gold-col', ' gold-colo', 'gold-colou', 'old-colour', 'ld-coloure', 'd-coloured', '-coloured ', 'coloured b', 'oloured br', 'loured bra', 'oured brac', 'ured brace', 'red bracel', 'ed bracele', 'd bracelet', ' bracelet ', 'bracelet w', 'racelet wh', 'acelet whi', 'celet whic', 'elet which', 'let which ', 'et which s', 't which sh', ' which she', 'which she ', 'hich she w', 'ich she wa', 'ch she was', 'h she was ', ' she was w', 'she was we', 'he was wea', 'e was wear', ' was weari', 'was wearin', 'as wearing', 's wearing ', ' wearing a', 'wearing an', 'earing and', 'aring and ', 'ring and t', 'ing and to', 'ng and too', 'g and took', ' and took ', 'and took h', 'nd took he', 'd took her', ' took her ', 'took her o', 'ook her ou', 'ok her out', 'k her out ', ' her out o', 'her out of', 'er out of ', 'r out of t', ' out of th', 'out of the', 'ut of the ', 't of the p', ' of the po', 'of the pol', 'f the poly', ' the polyc', 'the polycl', 'he polycli', 'e polyclin', ' polyclini', 'polyclinic', 'olyclinic.', 'lyclinic. ', 'yclinic.  ', 'clinic.  o', 'linic.  oh', 'inic.  oh ', 'nic.  oh t', 'ic.  oh th', 'c.  oh the', '.  oh then', '  oh then ', ' oh then g', 'oh then go', 'h then got', ' then got ', 'then got a', 'hen got a ', 'en got a t', 'n got a ta', ' got a tax', 'got a taxi', 'ot a taxi ', 't a taxi t', ' a taxi to', 'a taxi to ', ' taxi to t', 'taxi to ta', 'axi to tak', 'xi to take', 'i to take ', ' to take m', 'to take ma', 'o take mad', ' take mada', 'take madam', 'ake madam ', 'ke madam n', 'e madam ng', ' madam ng ', 'madam ng t', 'adam ng to', 'dam ng to ', 'am ng to n', 'm ng to nu', ' ng to nuh', 'ng to nuh,', 'g to nuh, ', ' to nuh, a', 'to nuh, as', 'o nuh, as ', ' nuh, as s', 'nuh, as sh', 'uh, as she', 'h, as she ', ', as she w', ' as she wa', 'as she was', 's she was ', ' she was l', 'she was lo', 'he was los', 'e was losi', ' was losin', 'was losing', 'as losing ', 's losing c', ' losing co', 'losing con', 'osing cons', 'sing consc', 'ing consci', 'ng conscio', 'g consciou', ' conscious', 'consciousn', 'onsciousne', 'nsciousnes', 'sciousness', 'ciousness.', 'iousness. ', 'ousness.  ', 'usness.  o', 'sness.  on', 'ness.  on ', 'ess.  on f', 'ss.  on fr', 's.  on fri', '.  on frid', '  on frida', ' on friday', 'on friday,', 'n friday, ', ' friday, d', 'friday, di', 'riday, dis', 'iday, dist', 'day, distr', 'ay, distri', 'y, distric', ', district', ' district ', 'district j', 'istrict ju', 'strict jud', 'trict judg', 'rict judge', 'ict judge ', 'ct judge g', 't judge gw', ' judge gwe', 'judge gwee', 'udge gwee ', 'dge gwee b', 'ge gwee ba', 'e gwee bac', ' gwee back', 'gwee backd', 'wee backda', 'ee backdat', 'e backdate', ' backdated', 'backdated ', 'ackdated o', 'ckdated oh', \"kdated oh'\", \"dated oh's\", \"ated oh's \", \"ted oh's s\", \"ed oh's se\", \"d oh's sen\", \" oh's sent\", \"oh's sente\", \"h's senten\", \"'s sentenc\", 's sentence', ' sentence ', 'sentence t', 'entence to', 'ntence to ', 'tence to s', 'ence to se', 'nce to sep', 'ce to sept', 'e to sept ', ' to sept  ', 'to sept  l', 'o sept  la', ' sept  las', 'sept  last', 'ept  last ', 'pt  last y', 't  last ye', '  last yea', ' last year', 'last year,', 'ast year, ', 'st year, w', 't year, wh', ' year, whe', 'year, when', 'ear, when ', 'ar, when h', 'r, when he', ', when he ', ' when he w', 'when he wa', 'hen he was', 'en he was ', 'n he was f', ' he was fi', 'he was fir', 'e was firs', ' was first', 'was first ', 'as first r', 's first re', ' first rem', 'first rema', 'irst reman', 'rst remand', 'st remande', 't remanded']\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-nLcyeIo5XCI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "a520adc1-0511-43fe-99ef-ffcd719246a2"
      },
      "source": [
        "# show the model output using predict function\n",
        "# Enter your code here:\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def sample(preds, temperature=0.2):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "  \n",
        "#sequences = tokenizer.texts_to_sequences(text_input)\n",
        "#data = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "print(\"Temperature: \", temperature)\n",
        "for epoch in range(1, 5):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(X, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text_input) - window_size - 1)\n",
        "    generated_text = text_input[start_index: start_index + window_size]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    #for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        #print('------ temperature:', temperature)\n",
        "    sys.stdout.write(generated_text)\n",
        "\n",
        "    # We generate 100 characters\n",
        "    for i in range(100):\n",
        "        sampled = np.zeros((1, window_size, len(chars)))\n",
        "        for t, char in enumerate(generated_text):\n",
        "            sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(sampled, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = chars[next_index]\n",
        "\n",
        "        generated_text += next_char\n",
        "        generated_text = generated_text[1:]\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature:  1.2\n",
            "epoch 1\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 35) for input Tensor(\"lstm_1_input_9:0\", shape=(None, 100, 35), dtype=float32), but it was called on an input with incompatible shape (None, 10, 35).\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9631 - acc: 0.4610\n",
            "--- Generating with seed: \"hat she had to take it before her medical check-up.  thinking that oh was one of the polyclinic staf\"\n",
            "hat she had to take it before her medical check-up.  thinking that oh was one of the polyclinic stafss woman to lefoutligicy, foundnessly. the name, funce. thenit is loss you.indeocy. yet his bedroom.\n",
            "epoch 2\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5886 - acc: 0.5376\n",
            "--- Generating with seed: \" , was waiting for her turn to see the doctor at queenstown polyclinic, he stole money from her hand\"\n",
            " , was waiting for her turn to see the doctor at queenstown polyclinic, he stole money from her hand. youdod once kneechpart to turn thisfus injusplyand talk, glated lauring me whise halfler's last of\n",
            "epoch 3\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3613 - acc: 0.6053\n",
            "--- Generating with seed: \"e it before her medical check-up.  thinking that oh was one of the polyclinic staff, madam ng took t\"\n",
            "e it before her medical check-up.  thinking that oh was one of the polyclinic staff, madam ng took through but shature that slowly man-rooler and suppose, said he.'you par that ifat the the centre nar\n",
            "epoch 4\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1870 - acc: 0.6451\n",
            "--- Generating with seed: \" wearing and took her out of the polyclinic.  oh then got a taxi to take madam ng to nuh, as she was\"\n",
            " wearing and took her out of the polyclinic.  oh then got a taxi to take madam ng to nuh, as she was thingono dis crackly. you , hek was seee her month madam naonxettation,  jumen kapytwayxuredfrom un\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JoBc7bGQ5XCK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "955a65d8-8aa7-4331-be10-65945763c656"
      },
      "source": [
        "model.fit(X, y, batch_size=128, epochs=1)\n",
        "\n",
        "text_input = input(\"Enter sentence to predict next character: \\n\")\n",
        "temperature = 0.2\n",
        "print('------ temperature:', temperature)\n",
        "print(\"Prediction: \")\n",
        "sys.stdout.write(text_input)\n",
        "\n",
        "\n",
        "sampled = np.zeros((1, len(text_input), len(chars)))\n",
        "for t, char in enumerate(text_input):\n",
        "    sampled[0, t, chars_to_indices[char]] = 1.\n",
        "\n",
        "preds = model.predict(sampled, verbose=0)[0]\n",
        "next_index = sample(preds, temperature)\n",
        "next_char = chars[next_index]\n",
        "\n",
        "text_input += next_char\n",
        "text_input = text_input[1:]\n",
        "\n",
        "\n",
        "sys.stdout.write(next_char)\n",
        "sys.stdout.flush()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 6ms/step - loss: 0.9041 - acc: 0.7452\n",
            "Enter sentence to predict next character: \n",
            "dogs are grea\n",
            "------ temperature: 0.2\n",
            "Prediction: \n",
            "dogs are great\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}